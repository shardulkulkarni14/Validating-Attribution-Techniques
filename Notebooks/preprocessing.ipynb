{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c8783eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19b421d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-11 20:53:36.691040: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-11 20:53:48.183203: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /scratch/juneja/python/lib/python3.8/site-packages/cv2/../../lib64:/usr/local/cuda-11.3/lib64:/scratch/juneja/python/lib:/usr/local/cuda-11.3/tensorRT-8.0/lib64:/usr/local/cuda-11.3/cudnn-8.2/lib64:/usr/local/cuda-11.3/nccl-2.9/lib64\n",
      "2023-10-11 20:53:48.183536: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /scratch/juneja/python/lib/python3.8/site-packages/cv2/../../lib64:/usr/local/cuda-11.3/lib64:/scratch/juneja/python/lib:/usr/local/cuda-11.3/tensorRT-8.0/lib64:/usr/local/cuda-11.3/cudnn-8.2/lib64:/usr/local/cuda-11.3/nccl-2.9/lib64\n",
      "2023-10-11 20:53:48.183570: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"from numpy import random\\nimport torch\\nimport torchvision\\nfrom torch.nn import functional as F\\nfrom PIL import Image\\nimport matplotlib.pyplot as plt\\nimport numpy as np\\nfrom torchvision import transforms\\nimport cv2\\nimport os\\nimport tensorflow as tf\\nfrom tensorflow import keras\\nimport scipy.stats as sci \";\n",
       "                var nbb_formatted_code = \"from numpy import random\\nimport torch\\nimport torchvision\\nfrom torch.nn import functional as F\\nfrom PIL import Image\\nimport matplotlib.pyplot as plt\\nimport numpy as np\\nfrom torchvision import transforms\\nimport cv2\\nimport os\\nimport tensorflow as tf\\nfrom tensorflow import keras\\nimport scipy.stats as sci\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from numpy import random\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.nn import functional as F\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "import cv2\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import scipy.stats as sci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "439bb43e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"#set proxy\\n\\nos.environ['HTTP_PROXY'] = 'http://fp.cs.ovgu.de:3210/'\\nos.environ['HTTPS_PROXY'] = 'http://fp.cs.ovgu.de:3210/'\";\n",
       "                var nbb_formatted_code = \"# set proxy\\n\\nos.environ[\\\"HTTP_PROXY\\\"] = \\\"http://fp.cs.ovgu.de:3210/\\\"\\nos.environ[\\\"HTTPS_PROXY\\\"] = \\\"http://fp.cs.ovgu.de:3210/\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# set proxy\n",
    "\n",
    "os.environ[\"HTTP_PROXY\"] = \"http://fp.cs.ovgu.de:3210/\"\n",
    "os.environ[\"HTTPS_PROXY\"] = \"http://fp.cs.ovgu.de:3210/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17b31d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Cannot parse: 13:0:         tensor = preprocess(image)\n",
      "Traceback (most recent call last):\n",
      "  File \"/scratch/juneja/python/lib/python3.8/site-packages/lab_black.py\", line 218, in format_cell\n",
      "    formatted_code = _format_code(cell)\n",
      "  File \"/scratch/juneja/python/lib/python3.8/site-packages/lab_black.py\", line 29, in _format_code\n",
      "    return format_str(src_contents=code, mode=FileMode())\n",
      "  File \"src/black/__init__.py\", line 1079, in format_str\n",
      "  File \"src/black/__init__.py\", line 1089, in _format_str_once\n",
      "  File \"src/black/parsing.py\", line 127, in lib2to3_parse\n",
      "black.parsing.InvalidInput: Cannot parse: 13:0:         tensor = preprocess(image)\n"
     ]
    }
   ],
   "source": [
    "def process(image, output):\n",
    "    size = (300, 300)\n",
    "    image = image.resize(size)\n",
    "    #mean and std from ImageNet\n",
    "    normalize = transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "        )\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "        ])\n",
    "    tensor = preprocess(image)\n",
    "    # reshape 4D tensor (N, C, H, W)\n",
    "    tensor = tensor.unsqueeze(0)\n",
    "    return tensor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
