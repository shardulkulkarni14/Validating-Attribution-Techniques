{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7065a0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25efd634",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_perturb(out_dir, image, saliency_map, perturbation_strength=0.05, saliency_threshold=0.5, num_iterations=1, perturbation_prob=0.1):\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.mkdir(out_dir)\n",
    "    \n",
    "    # Move the image tensor to the device of the saliency_map tensor\n",
    "    image = image.to(saliency_map.device)\n",
    "    \n",
    "    # Get the top n percent of saliency values\n",
    "    saliency_values = saliency_map.view(-1)\n",
    "    threshold = torch.kthvalue(saliency_values, int((1 - saliency_threshold) * saliency_values.size(0)) + 1).values\n",
    "    \n",
    "    mask = torch.gt(saliency_map, threshold).float()\n",
    "    \n",
    "    # Perturb the image for a given number of iterations only at a random subset of the mask where the value is 1\n",
    "    perturbed_image = image.clone()\n",
    "    for i in range(num_iterations):\n",
    "        perturbation_mask = (mask == 1) * (torch.rand_like(mask) < perturbation_prob).float()\n",
    "        noise = torch.randn_like(perturbed_image) * perturbation_strength\n",
    "        perturbation_mask = perturbation_mask.to(perturbed_image.device)  # Move perturbation_mask to the same device as perturbed_image\n",
    "        noise = noise.to(perturbed_image.device)  # Move noise to the same device as perturbed_image\n",
    "        perturbed_image = perturbed_image + perturbation_mask * noise\n",
    "        perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
    "        \n",
    "    return perturbed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8105b92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perturb():\n",
    "for i in range(10):\n",
    "\n",
    "  perturbed_tensor = perturb_image(tensor, cam, perturbation_strength, saliency_threshold, 1, perturbation_prob)\n",
    "  image_array = perturbed_tensor.squeeze().permute(1,2,0).detach().cpu().numpy()\n",
    "  image_array = (image_array - np.min(image_array)) / (np.max(image_array) - np.min(image_array))\n",
    "  fig, ax = plt.subplots()\n",
    "  ax.imshow(image_array, cmap = 'turbo', alpha = 0.8)\n",
    "  fig.savefig(f\"/project/validating_attribution_techniques/shardul/output/noisy_images/{i}_noise.jpeg\")\n",
    "    \n",
    "  fig, ax = plt.subplots()\n",
    "  \n",
    "  #save only models \n",
    "  #get class of the perturbed image\n",
    "  perturbed_tensor = perturbed_tensor.type_as(gpu_reference_tensor)\n",
    "  saliency_map_perturbed, perturbed_idx = wrapped_model(perturbed_tensor)\n",
    "  with torch.no_grad():\n",
    "    output = model(perturbed_tensor)\n",
    "    perturbed_class = torch.argmax(output).item()\n",
    "    prob = torch.softmax(output, dim=1)[0, perturbed_class].item()\n",
    "  img = reverse_normalize(perturbed_tensor)\n",
    "  heatmap = visualize(img, saliency_map_perturbed)\n",
    "  hm = (heatmap.squeeze().numpy().transpose(1, 2, 0))\n",
    "  ax.imshow(hm, cmap='turbo', alpha = 0.8)\n",
    "  ax.set_title(f\"Class: {classes[perturbed_idx]}({prob*100:.2f}%)\")\n",
    "  fig.savefig(f\"/project/validating_attribution_techniques/shardul/output/saliency/after_noise/{i}_{idx2label[idx]}.jpeg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb95fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_grey_patch(path, image, top_left_x, top_left_y, patch_size):\n",
    "    patched_image = np.array(image, copy=True)\n",
    "    patched_image[top_left_y:top_left_y + patch_size,\n",
    "                  top_left_x:top_left_x + patch_size, :] = 0\n",
    "    img = keras.preprocessing.image.array_to_img(patched_image)\n",
    "    print(path)\n",
    "    img.save(path)\n",
    "    print(np.shape(patched_image))\n",
    "    return patched_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cc1eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#have a version with multiple occlusion blocks\n",
    "\n",
    "def occu_perturb(image_tensor, path):\n",
    "    PATCH_SIZE = 60\n",
    "    #Putting the patch over the image\n",
    "    image = tf.keras.preprocessing.image.load_img(\n",
    "    image_path, target_size=(224, 224))\n",
    "    image = tf.keras.preprocessing.image.img_to_array(image)\n",
    "    i = 0\n",
    "    # Iterate the patch over the image\n",
    "    for top_left_x in range(0, image.shape[0], PATCH_SIZE):\n",
    "        for top_left_y in range(0, image.shape[1], PATCH_SIZE):\n",
    "        \n",
    "        if not os.path.exists(path)\n",
    "            os.mkdir(path+'occu_img')\n",
    "\n",
    "        path = path + \\\n",
    "            str(i)+'.jpg'\n",
    "        i += 1\n",
    "        patched_image = apply_grey_patch(\n",
    "            path, image, top_left_x, top_left_y, PATCH_SIZE)\n",
    "        patched_image = patched_image.astype('float32') / 255.0\n",
    "    return"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
