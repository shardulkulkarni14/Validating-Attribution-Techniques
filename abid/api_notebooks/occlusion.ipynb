{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a17bb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp occlusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "680ecfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d68a05b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def apply_patch(image, top_left_x, top_left_y, patch_size):\n",
    "    \"\"\"\n",
    "    Zeros-out a square region within the image\n",
    "    \n",
    "    input :\n",
    "      - image : ndarray (Image to be occluded)\n",
    "      - top_left_x : int (Top coordinate of the patch)\n",
    "      - top_left_y : int (Left coordinate of the patch)\n",
    "      - patch_size : int (Size of the square patch)\n",
    "      \n",
    "    return :\n",
    "      - patched_image : ndarray (Occluded image)\n",
    "    \"\"\"\n",
    "    patched_image = np.copy(image)\n",
    "    patched_image[top_left_y : top_left_y+patch_size,\n",
    "                  top_left_x : top_left_x+patch_size, :] = 0\n",
    "    return patched_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e2f75fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def generate_img_occlusion_list(img, patch_size, saliency=None, saliency_reduce_func=np.mean):\n",
    "    \"\"\"\n",
    "    Generates a list of img that has been sequentially occluded according to the patch_size,\n",
    "    whereby `stride=patch_size`.\n",
    "    \n",
    "    input :\n",
    "      - img : ndarray (Image to create occluded version of)\n",
    "      - patch_size : int (Size of the occluded patch)\n",
    "      - saliency : ndarray (optional saliency map to generate a reduced saliency value for each occluded region)\n",
    "      - saliency_reduce_func : function (optional iterative-wise function to reduce saliency value into a value)\n",
    "      \n",
    "    return :\n",
    "      - occlusion_img_list : ndarray (Array of occluded versions of the image)\n",
    "      - occlusion_saliency_statistic : ndarray|None (Array of reduce saliency value for each patch location)\n",
    "    \"\"\"\n",
    "    occlusion_img_list = []\n",
    "    occlusion_saliency_statistic = []\n",
    "    if saliency is not None:\n",
    "        saliency = np.array(Image.fromarray(saliency).resize((img.shape[0], img.shape[1])))\n",
    "    \n",
    "    for top_left_y in range(0, img.shape[1], patch_size):\n",
    "        for top_left_x in range(0, img.shape[0], patch_size):\n",
    "            patched_image = apply_patch(img, top_left_x, top_left_y, patch_size).astype('float32') / 255.0\n",
    "            occlusion_img_list.append(patched_image)\n",
    "            if saliency is not None:\n",
    "                occlusion_saliency_statistic.append(saliency_reduce_func(saliency[top_left_y : top_left_y+patch_size,\n",
    "                                                                                  top_left_x : top_left_x+patch_size]))\n",
    "            \n",
    "    return np.array(occlusion_img_list), (np.array(occlusion_saliency_statistic) if saliency is not None else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d288171",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_nonintersecting_patch_coord_mask(height, width, num_patch, patch_size):\n",
    "    \"\"\"\n",
    "    Returns the coordinate of occlusion patches, as well as a binary mask where patch location have been zero'd out.\n",
    "    The returned patch locations are such that they will not intersect with each other under any circumstance.\n",
    "    Due to the aformentioned rule, if not enough space available, the function might return smaller number of\n",
    "    patches than requested.\n",
    "    \n",
    "    input :\n",
    "      - height : int (height of the desired mask)\n",
    "      - width : int (width of the desired mask)\n",
    "      - num_patch : int (maximum number of patches present in one occluded image)\n",
    "      - patch_size : int (height and width of the patch)\n",
    "      \n",
    "    return :\n",
    "      - patch_coords : ndarray (Array containing the 2D coordinates for the top-left location of patches)\n",
    "      - mask_np : ndarray (A bianry mask that has been generated using the coodinates)\n",
    "    \"\"\"\n",
    "    mask_np = np.ones((height, width))\n",
    "    allowed_mask_pos = np.ones((height, width))\n",
    "    allowed_mask_pos[width-patch_size:, :] = 0\n",
    "    allowed_mask_pos[:, height-patch_size:] = 0\n",
    "    \n",
    "    sample_x = np.random.choice(np.where(np.any(allowed_mask_pos, 1, where=1))[0])\n",
    "    sample_y = np.random.choice(np.where(allowed_mask_pos[sample_x,] != 0)[0])\n",
    "    \n",
    "    allowed_mask_pos[np.clip(sample_x-patch_size+1, 0, sample_x):sample_x+patch_size,\n",
    "                     np.clip(sample_y-patch_size+1, 0, sample_y):sample_y+patch_size] = 0\n",
    "    \n",
    "    mask_np[sample_x:sample_x+patch_size, sample_y:sample_y+patch_size] = 0\n",
    "    patch_coords = np.array([[sample_x, sample_y]])\n",
    "    for _ in range(num_patch-1):\n",
    "        remain_x = np.where(np.any(allowed_mask_pos, 1, where=1))[0]\n",
    "        if remain_x.shape[0] == 0:\n",
    "            break\n",
    "            \n",
    "        sample_x = np.random.choice(remain_x)\n",
    "        sample_y = np.random.choice(np.where(allowed_mask_pos[sample_x,] != 0)[0])\n",
    "        allowed_mask_pos[np.clip(sample_x-patch_size+1, 0, sample_x):sample_x+patch_size,\n",
    "                         np.clip(sample_y-patch_size+1, 0, sample_y):sample_y+patch_size] = 0\n",
    "        \n",
    "        mask_np[sample_x:sample_x+patch_size, sample_y:sample_y+patch_size] = 0\n",
    "        patch_coords = np.vstack((patch_coords, np.array([sample_x, sample_y])))\n",
    "        \n",
    "    return patch_coords, mask_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ec5373",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def generate_multipatch_occlusion_list_reduce_saliency(img : np.ndarray, patch_size : int, multipatch_num : int, steps : int, saliency=None, saliency_reduce_func=np.sum):\n",
    "    \"\"\"\n",
    "    Generates a list of images that has been occluded on multiple locations, defined by multipatch_num,\n",
    "    whereby the location of each patch is random and the patches never overlap.\n",
    "    \n",
    "    input :\n",
    "      - img : ndarray (Image to create occluded version of)\n",
    "      - patch_size : int (Size of the occluded patch)\n",
    "      - multipatch_num : int (The maximum number of patches in the occluded image)\n",
    "      - steps : int (Total number of occluded image)\n",
    "      - saliency : ndarray (optional saliency map to generate a reduced saliency value for each occluded version of the image)\n",
    "      - saliency_reduce_func : function (optional iterative-wise function to reduce saliency values into a value)\n",
    "      \n",
    "    return :\n",
    "      - occlusion_img_list : ndarray (Array of occluded versions of the image)\n",
    "      - occlusion_saliency_statistic : ndarray|None (Array of reduce saliency value for each patch location)\n",
    "    \"\"\"\n",
    "    occlusion_img_list = []\n",
    "    occlusion_saliency_statistic = []\n",
    "    if saliency is not None:\n",
    "        occlusion_saliency_statistic = []\n",
    "        saliency = np.array(Image.fromarray(saliency).resize((img.shape[0], img.shape[1])))\n",
    "    \n",
    "    patch_locs = np.random.randint(0, img.shape[0]-patch_size, (steps, multipatch_num, 2))\n",
    "    for step_idx in range(steps):\n",
    "        # saliency_value = \n",
    "        patch_coords, mask = get_patch_coord_mask(img.shape[0], img.shape[1], multipatch_num, patch_size)\n",
    "        patched_image = img * np.expand_dims(mask, -1)\n",
    "        patched_image = patched_image.astype('float32') / 255.0\n",
    "        occlusion_img_list.append(patched_image)\n",
    "        if saliency is not None:\n",
    "            occlusion_saliency_statistic.append(saliency_reduce_func(saliency * np.logical_not(mask)))\n",
    "        \n",
    "    return np.array(occlusion_img_list), (np.array(occlusion_saliency_statistic) if saliency is not None else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0236bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.export import nb_export\n",
    "nb_export('occlusion.ipynb', '../../commons/api/method')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd66844",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
