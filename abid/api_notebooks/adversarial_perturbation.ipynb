{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec2f36af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp adv_perturb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a4900af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Oct 27 17:19:12 2023       \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 535.86.10              Driver Version: 535.86.10    CUDA Version: 12.2     |\r\n",
      "|-----------------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                      |               MIG M. |\r\n",
      "|=========================================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce RTX 2080 Ti     Off | 00000000:B1:00.0 Off |                  N/A |\r\n",
      "| 32%   54C    P2              79W / 250W |    807MiB / 11264MiB |     36%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "|   1  NVIDIA GeForce RTX 2080 Ti     Off | 00000000:B2:00.0 Off |                  N/A |\r\n",
      "| 22%   25C    P8               1W / 250W |      3MiB / 11264MiB |      0%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "|   2  NVIDIA GeForce RTX 2080 Ti     Off | 00000000:DA:00.0 Off |                  N/A |\r\n",
      "| 22%   24C    P8              16W / 250W |      3MiB / 11264MiB |      0%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "|   3  NVIDIA GeForce RTX 2080 Ti     Off | 00000000:DB:00.0 Off |                  N/A |\r\n",
      "| 22%   24C    P8              21W / 250W |      3MiB / 11264MiB |      0%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                            |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\r\n",
      "|        ID   ID                                                             Usage      |\r\n",
      "|=======================================================================================|\r\n",
      "+---------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9fcd709",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"2,3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "442232e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU:0 NVIDIA GeForce RTX 2080 Ti\n",
      "GPU:1 NVIDIA GeForce RTX 2080 Ti\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "ngpu = torch.cuda.device_count()\n",
    "for gpu_id in range(ngpu):\n",
    "    gpu = torch.cuda.get_device_name(gpu_id)\n",
    "    print(f\"GPU:{gpu_id} {gpu}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70f63c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from typing import Any, Callable, Optional, Tuple, Union\n",
    "\n",
    "import torch\n",
    "from captum._utils.common import (\n",
    "    _format_additional_forward_args,\n",
    "    _format_output,\n",
    "    _format_tensor_into_tuples,\n",
    "    _is_tuple,\n",
    "    _select_targets,\n",
    ")\n",
    "from captum._utils.gradient import (\n",
    "    apply_gradient_requirements,\n",
    "    compute_gradients,\n",
    "    undo_gradient_requirements,\n",
    ")\n",
    "from captum._utils.typing import TensorOrTupleOfTensorsGeneric\n",
    "from captum.log import log_usage\n",
    "from captum.robust._core.perturbation import Perturbation\n",
    "from torch import Tensor\n",
    "\n",
    "class FGSM_MOD(Perturbation):\n",
    "    def __init__(\n",
    "        self,\n",
    "        forward_func: Callable,\n",
    "        loss_func: Optional[Callable] = None,\n",
    "        lower_bound: float = float(\"-inf\"),\n",
    "        upper_bound: float = float(\"inf\"),\n",
    "        anti_adv: bool = False\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.forward_func = forward_func\n",
    "        self.loss_func = loss_func\n",
    "        self.bound = lambda x: torch.clamp(x, min=lower_bound, max=upper_bound)\n",
    "        self.zero_thresh = 10**-6\n",
    "        self.anti_adv = anti_adv\n",
    "\n",
    "    @log_usage()\n",
    "    def perturb(\n",
    "        self,\n",
    "        inputs: TensorOrTupleOfTensorsGeneric,\n",
    "        epsilon: float,\n",
    "        target: Any,\n",
    "        additional_forward_args: Any = None,\n",
    "        targeted: bool = False,\n",
    "        mask: Optional[TensorOrTupleOfTensorsGeneric] = None,\n",
    "    ) -> TensorOrTupleOfTensorsGeneric:\n",
    "        is_inputs_tuple = _is_tuple(inputs)\n",
    "        inputs: Tuple[Tensor, ...] = _format_tensor_into_tuples(inputs)\n",
    "        masks: Union[Tuple[int, ...], Tuple[Tensor, ...]] = (\n",
    "            _format_tensor_into_tuples(mask)\n",
    "            if (mask is not None)\n",
    "            else (1,) * len(inputs)\n",
    "        )\n",
    "        gradient_mask = apply_gradient_requirements(inputs)\n",
    "\n",
    "        def _forward_with_loss() -> Tensor:\n",
    "            additional_inputs = _format_additional_forward_args(additional_forward_args)\n",
    "            outputs = self.forward_func(  # type: ignore\n",
    "                *(*inputs, *additional_inputs)  # type: ignore\n",
    "                if additional_inputs is not None\n",
    "                else inputs\n",
    "            )\n",
    "            if self.loss_func is not None:\n",
    "                return self.loss_func(outputs, target)\n",
    "            else:\n",
    "                loss = -torch.log(outputs)\n",
    "                return _select_targets(loss, target)\n",
    "\n",
    "        grads = compute_gradients(_forward_with_loss, inputs)\n",
    "        undo_gradient_requirements(inputs, gradient_mask)\n",
    "        if self.anti_adv:\n",
    "            perturbed_inputs = self._anti_perturb(inputs, grads, epsilon, targeted, masks)\n",
    "        else:\n",
    "            perturbed_inputs = self._perturb(inputs, grads, epsilon, targeted, masks)\n",
    "        perturbed_inputs = tuple(\n",
    "            self.bound(perturbed_inputs[i]) for i in range(len(perturbed_inputs))\n",
    "        )\n",
    "        return _format_output(is_inputs_tuple, perturbed_inputs)\n",
    "\n",
    "    def _perturb(\n",
    "        self,\n",
    "        inputs: Tuple,\n",
    "        grads: Tuple,\n",
    "        epsilon: float,\n",
    "        targeted: bool,\n",
    "        masks: Tuple,\n",
    "    ) -> Tuple:\n",
    "        multiplier = -1 if targeted else 1\n",
    "        inputs = tuple(\n",
    "            torch.where(\n",
    "                torch.abs(grad) > self.zero_thresh,\n",
    "                inp + multiplier * epsilon * torch.sign(grad) * mask,\n",
    "                inp,\n",
    "            )\n",
    "            for grad, inp, mask in zip(grads, inputs, masks)\n",
    "        )\n",
    "        return inputs\n",
    "    \n",
    "    def _anti_perturb(\n",
    "        self,\n",
    "        inputs: Tuple,\n",
    "        grads: Tuple,\n",
    "        epsilon: float,\n",
    "        targeted: bool,\n",
    "        masks: Tuple,\n",
    "    ) -> Tuple:\n",
    "        multiplier = -1 if targeted else 1\n",
    "        inputs = tuple(\n",
    "            torch.where(\n",
    "                torch.abs(grad) > self.zero_thresh,\n",
    "                inp - multiplier * epsilon * torch.sign(grad) * mask,\n",
    "                inp,\n",
    "            )\n",
    "            for grad, inp, mask in zip(grads, inputs, masks)\n",
    "        )\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9000e410",
   "metadata": {},
   "source": [
    "### Adversarial Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8079f525",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def adversarial_noise(inputs, model, class_idx, epsilon, lower_bound=-1, upper_bound=1, anti_adv=False, mask=None):\n",
    "    \"\"\"\n",
    "    Adds (anti-)adversarial noise to an image and returns the modified image.\n",
    "    \n",
    "    input :\n",
    "      - inputs : torch.tensor (A torch tensor with shape (channels, height, width))\n",
    "      - model : function (Model function which output probability)\n",
    "      - class_idx : int (Index of the class based on which we apply (anti-)adversarial noise)\n",
    "      - epsilon : float32 (Intensity of the noise added, lower value changes the image less)\n",
    "      - lower_bound : float32 (The minimum value below which we would clamp)\n",
    "      - upper_bound : float32 (The maximum value above which we would clamp)\n",
    "      - anti_adv : boolean (Should the method attack the class_idx)\n",
    "      - mask : ndarray (Array of float32 or int32, modulating the noises added based on their values)\n",
    "      \n",
    "    return :\n",
    "      - perturbed_img : torch.tensor (Tensor containing the perturbed image)\n",
    "    \"\"\"\n",
    "    fgsm = FGSM_MOD(model, lower_bound=lower_bound, upper_bound=upper_bound, anti_adv=anti_adv)\n",
    "    perturbed_img = fgsm.perturb(inputs, epsilon=epsilon, target=class_idx, mask=mask)\n",
    "    return perturbed_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abddae62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.export import nb_export\n",
    "nb_export('adversarial_perturbation.ipynb', '../../commons/api/method')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6674c37f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
