{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71d663f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun  1 01:29:22 2023       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 525.60.13    Driver Version: 525.60.13    CUDA Version: 12.0     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:B1:00.0 Off |                  N/A |\r\n",
      "| 22%   23C    P8     5W / 250W |  10457MiB / 11264MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  NVIDIA GeForce ...  Off  | 00000000:B2:00.0 Off |                  N/A |\r\n",
      "| 22%   31C    P2    72W / 250W |    335MiB / 11264MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   2  NVIDIA GeForce ...  Off  | 00000000:DA:00.0 Off |                  N/A |\r\n",
      "| 22%   25C    P8    17W / 250W |    335MiB / 11264MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   3  NVIDIA GeForce ...  Off  | 00000000:DB:00.0 Off |                  N/A |\r\n",
      "| 22%   25C    P8    21W / 250W |    335MiB / 11264MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd693d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-01 01:29:27.015238: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-01 01:29:29.400389: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.3/lib64:/scratch/hashimi/python/lib:/usr/local/cuda-11.3/tensorRT-8.0/lib64:/usr/local/cuda-11.3/cudnn-8.2/lib64:/usr/local/cuda-11.3/nccl-2.9/lib64\n",
      "2023-06-01 01:29:29.400619: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.3/lib64:/scratch/hashimi/python/lib:/usr/local/cuda-11.3/tensorRT-8.0/lib64:/usr/local/cuda-11.3/cudnn-8.2/lib64:/usr/local/cuda-11.3/nccl-2.9/lib64\n",
      "2023-06-01 01:29:29.400641: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  4\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "# Set TensorFlow to use the first GPU (assuming you have at least one GPU available)\n",
    "tf.config.experimental.set_visible_devices(tf.config.experimental.list_physical_devices('GPU')[1], 'GPU')\n",
    "\n",
    "# # Enable memory growth for the GPU\n",
    "# tf.config.experimental.set_memory_growth(tf.config.experimental.list_physical_devices('GPU')[1], True)\n",
    "\n",
    "# # Rest of your TensorFlow code...\n",
    "# ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2521d48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-03 12:26:39.238341: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-03 12:26:42.173729: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.3/lib64:/scratch/hashimi/python/lib:/usr/local/cuda-11.3/tensorRT-8.0/lib64:/usr/local/cuda-11.3/cudnn-8.2/lib64:/usr/local/cuda-11.3/nccl-2.9/lib64\n",
      "2023-06-03 12:26:42.174046: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.3/lib64:/scratch/hashimi/python/lib:/usr/local/cuda-11.3/tensorRT-8.0/lib64:/usr/local/cuda-11.3/cudnn-8.2/lib64:/usr/local/cuda-11.3/nccl-2.9/lib64\n",
      "2023-06-03 12:26:42.174076: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow.keras.layers as tfkl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc423b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the data and tokenization (character-wise)\n",
    "with open('shakespeare.txt', 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "    \n",
    "characters = sorted(list(set(text)))\n",
    "num_vocab = len(characters)\n",
    "\n",
    "str_to_idx = {char:idx for idx, char in enumerate(characters)}\n",
    "idx_to_str = {idx:char for idx, char in enumerate(characters)}\n",
    "\n",
    "def encoder(string): return [str_to_idx[i] for i in string]\n",
    "def decoder(idx_list): return ''.join([idx_to_str[i] for i in idx_list])\n",
    "\n",
    "_data = tf.constant(encoder(text), dtype=tf.int64)\n",
    "data_split = 0.85\n",
    "train_data = _data[:int(data_split*_data.shape[0])]\n",
    "test_data = _data[int(data_split*_data.shape[0]):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22cb77da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(948084, 1115394)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape[0], len(_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a55d1100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'First Citizen:\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder(train_data[0:15].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c0481fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE(Abid): Hyperparameters\n",
    "batch_size = 64\n",
    "context_length = 256\n",
    "learning_rate = 2e-4\n",
    "embed_dim = 384\n",
    "num_heads = 6\n",
    "num_layers = 6\n",
    "dropout_rate = 0.2\n",
    "max_iterations = 4_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c62fcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_batch(batch_size, is_train=True):\n",
    "    data = train_data if is_train else test_data\n",
    "    rand_idxs = tf.random.uniform(shape=[batch_size],\n",
    "                                  minval=0,\n",
    "                                  maxval=(data.shape[0] - context_length),\n",
    "                                  dtype=tf.int64)\n",
    "    x_data = tf.concat([\n",
    "                        tf.expand_dims(data[idx:idx+context_length], axis=0) for idx in rand_idxs\n",
    "                       ], axis=0)\n",
    "    y_data = tf.concat([\n",
    "                        tf.expand_dims(data[idx+1:idx+context_length+1], axis=0) for idx in rand_idxs\n",
    "                       ], axis=0)\n",
    "    return x_data, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f5cff62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 256]), TensorShape([64, 256]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = get_next_batch(64)\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00bbfbaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([32, 20, 33, 25, 14]), array([20, 33, 25, 14, 17]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0, context_length-5:].numpy(), y[0, context_length-5:].numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f24c0c",
   "metadata": {},
   "source": [
    "$$\\displaystyle Attention(Q, K, V) = softmax(\\frac{(QK^T)*M_{tril}}{\\sqrt{d_k}})V$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b0ea53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(tfkl.Layer):\n",
    "    def __init__(self, head_size, context_length, name = \"head\"):\n",
    "        super(Head, self).__init__(name=name)\n",
    "        self.key = tfkl.Dense(head_size, use_bias=False)\n",
    "        self.query = tfkl.Dense(head_size, use_bias=False)        \n",
    "        self.value = tfkl.Dense(head_size, use_bias=False)\n",
    "        self.tril = tf.Variable(tf.cast(\n",
    "                                        tf.linalg.band_part(tf.ones((context_length, context_length)), -1, 0),\n",
    "                                        tf.bool\n",
    "                                        ),\n",
    "                                trainable=False)\n",
    "        \n",
    "        self.dropout = tfkl.Dropout(rate=dropout_rate)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "            Input : (B, T, C)\n",
    "            \n",
    "            B : Batch\n",
    "            T : Token\n",
    "            C : embed_dim\n",
    "        \"\"\"\n",
    "        _, _, C = inputs.shape\n",
    "        k = self.key(inputs) # Shape : (B, T, head_size)\n",
    "        q = self.query(inputs) # Shape : (B, T, head_size)\n",
    "        v = self.value(inputs) # Shape : (B, T, head_size)\n",
    "        # NOTE(Abid): Dot product masked self-attention\n",
    "        weights = q @ tf.transpose(k, perm=[0, 2, 1]) * C**-0.5 # Shape: (B, Wq, Wk)\n",
    "        weights = tf.where(self.tril, weights, float('-inf'))\n",
    "        weights = tf.nn.softmax(weights, axis=-1) # Normalize across the query dimension\n",
    "        weights = self.dropout(weights)\n",
    "        \n",
    "        return tf.matmul(weights, v) # (B, Wq, Wk) . (B, T, head_size) -> (B, T, head_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66c78694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 7, 10), dtype=float32, numpy=\n",
       "array([[[ 2.1266775 , -0.41531247, -2.304038  ,  1.7987556 ,\n",
       "         -1.6973717 , -0.4803359 ,  0.04099652, -0.24068457,\n",
       "         -0.20437169,  3.7679799 ],\n",
       "        [ 0.2817127 , -0.2714178 , -0.36797982,  0.30827332,\n",
       "         -2.4097033 ,  1.2224154 ,  0.42525762,  1.1447749 ,\n",
       "          0.6938753 ,  1.5345342 ],\n",
       "        [ 1.4629328 , -0.57707345, -1.230379  ,  1.1464357 ,\n",
       "         -1.4589345 ,  0.21226065, -0.20691413,  0.46568716,\n",
       "          0.19696167,  2.5874577 ],\n",
       "        [ 0.2317805 , -0.22312945,  0.24044028,  0.35871542,\n",
       "         -1.5233091 ,  0.94416434,  0.37654433,  1.1855155 ,\n",
       "          0.42087865,  1.0436945 ],\n",
       "        [ 1.0228122 , -0.53756744,  0.25492057,  0.5618928 ,\n",
       "         -0.29603082,  0.5919165 ,  0.10874847,  1.4014163 ,\n",
       "          0.3468199 ,  0.7130613 ],\n",
       "        [ 0.64294046,  0.095405  , -0.686411  ,  1.1214666 ,\n",
       "         -1.4347806 , -0.06384039,  0.43832386,  0.26387972,\n",
       "         -0.11089922,  1.6661055 ],\n",
       "        [-0.31074667,  0.26406628,  0.04453709,  0.7859607 ,\n",
       "         -0.25925452,  0.31584096,  1.2111332 ,  0.82562095,\n",
       "         -1.2595248 ,  0.15849322]]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # Checking if the head works\n",
    "head = Head(10, 7)\n",
    "ex_input = tf.random.normal((1, 7, 30))\n",
    "# head(ex_input)\n",
    "key = head.key(ex_input)\n",
    "query = head.query(ex_input)\n",
    "value = head.value(ex_input)\n",
    "weights = query @ tf.transpose(key, perm=[0, 2, 1]) * 30**-0.5\n",
    "weights = tf.where(head.tril, weights, float('-inf'))\n",
    "weights = tf.nn.softmax(weights, axis=-1)\n",
    "weights = head.dropout(weights)\n",
    "tf.matmul(weights, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "85cfc179",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MHA(tfkl.Layer):\n",
    "    def __init__(self, num_heads, head_size, context_length):\n",
    "        super(MHA, self).__init__(name=\"MultiHeadAttention\")\n",
    "        self.heads = [Head(head_size, context_length, \"head_\"+str(i+1)) for i in range(num_heads)]\n",
    "        # NOTE(Abid): This projection is used for when the concatenated values are large/smaller\n",
    "        #             in dimension than embed_dim. If that were to be the case, we wouldn't be able\n",
    "        #             to add the residual connections\n",
    "        self.proj = tfkl.Dense(embed_dim)\n",
    "        self.dropout = tfkl.Dropout(rate=dropout_rate)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "            Input : (B, T, C)\n",
    "            \n",
    "            B : Batch\n",
    "            T : Token\n",
    "            C : embed_dim\n",
    "        \"\"\"\n",
    "        output = tf.concat([head(inputs) for head in self.heads], axis=-1) # Shape : (B, T, num_head*head_size)\n",
    "        output = self.proj(output) # Shape : (B, T, C=embed_dim)\n",
    "        output = self.dropout(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0a829a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(tfkl.Layer):\n",
    "    def __init__(self, embed_dim):\n",
    "        super(FeedForward, self).__init__(name=\"feedforward\")\n",
    "        self.ff = tf.keras.Sequential([\n",
    "            tfkl.Dense(4*embed_dim, activation='relu'),\n",
    "            tfkl.Dense(embed_dim),\n",
    "            tfkl.Dropout(rate=dropout_rate)\n",
    "        ])\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "            Input : (B, T, C)\n",
    "            \n",
    "            B : Batch\n",
    "            T : Token\n",
    "            C : embed_dim\n",
    "        \"\"\"\n",
    "        return self.ff(inputs) # Shape : (B, T, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ce28828",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(tfkl.Layer):\n",
    "    def __init__(self, embed_dim, num_head, context_length, name='block'):\n",
    "        super(Block, self).__init__(name=name)\n",
    "        head_size = embed_dim // num_head\n",
    "        self.mha = MHA(num_head, head_size, context_length)\n",
    "        self.ff = FeedForward(embed_dim)\n",
    "        self.lnorm_1 = tfkl.LayerNormalization()\n",
    "        self.lnorm_2 = tfkl.LayerNormalization()\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "            Input : (B, T, C)\n",
    "            \n",
    "            B : Batch\n",
    "            T : Token\n",
    "            C : embed_dim\n",
    "        \"\"\"\n",
    "        output = inputs + self.mha(self.lnorm_1(inputs)) # Shape : (B, T, C)\n",
    "        return output + self.ff(self.lnorm_2(output))  # Shape : (B, T, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1b1da0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT(tf.keras.Model):\n",
    "    def __init__(self, num_vocab, embed_dim, context_length, num_layers, num_heads):\n",
    "        super(GPT, self).__init__(name=\"poor_mans_gpt\")\n",
    "        self.token_embedding = tfkl.Embedding(num_vocab, embed_dim)\n",
    "        self.positional_embedding = tfkl.Embedding(context_length, embed_dim)\n",
    "        self.blocks = tf.keras.Sequential([Block(embed_dim, num_heads, context_length, \"block_\"+str(i+1)) for i in range(num_layers)])\n",
    "        self.lnorm = tfkl.LayerNormalization()\n",
    "        self.prob_head = tfkl.Dense(num_vocab)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "            Input : (B, T)\n",
    "            \n",
    "            B : Batch\n",
    "            T : Token\n",
    "        \"\"\"\n",
    "        B, T = inputs.shape\n",
    "        token_embed = self.token_embedding(inputs) # Shape : (B, T, C=embed_dim)\n",
    "        position_embed = self.positional_embedding(tf.range(T)) # Shape :(T, C)\n",
    "        # NOTE(Abid): Broadcast here\n",
    "        output = token_embed + position_embed # Shape : (B, T, C)\n",
    "        output = self.blocks(output) # Shape : (B, T, C)\n",
    "        output = self.lnorm(output)\n",
    "        probs = self.prob_head(output) # Shape : (B, T, num_vocab)\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ad2b8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt = GPT(num_vocab, embed_dim, context_length, num_layers, num_heads)\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "optim = tf.optimizers.Adam(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a8bd685a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function(jit_compile=True)\n",
    "def train_gpt(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = gpt(x)\n",
    "        loss = loss_fn(y, logits)\n",
    "    grads = tape.gradient(loss, gpt.trainable_variables)\n",
    "    optim.apply_gradients(zip(grads, gpt.trainable_variables))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8566c463",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0, Training Loss: 4.371750831604004\n",
      "Iter: 50, Training Loss: 3.2318971157073975\n",
      "Iter: 100, Training Loss: 2.641303539276123\n",
      "Iter: 150, Training Loss: 2.5314390659332275\n",
      "Iter: 200, Training Loss: 2.4863147735595703\n",
      "Iter: 250, Training Loss: 2.4338483810424805\n",
      "Iter: 300, Training Loss: 2.4210453033447266\n",
      "Iter: 350, Training Loss: 2.3864338397979736\n",
      "Iter: 400, Training Loss: 2.2870495319366455\n",
      "Iter: 450, Training Loss: 2.202235698699951\n",
      "Iter: 500, Training Loss: 2.1372435092926025\n",
      "Iter: 550, Training Loss: 2.084388256072998\n",
      "Iter: 600, Training Loss: 2.0408549308776855\n",
      "Iter: 650, Training Loss: 1.9649531841278076\n",
      "Iter: 700, Training Loss: 1.893986463546753\n",
      "Iter: 750, Training Loss: 1.8385785818099976\n",
      "Iter: 800, Training Loss: 1.7673579454421997\n",
      "Iter: 850, Training Loss: 1.7243809700012207\n",
      "Iter: 900, Training Loss: 1.6937110424041748\n",
      "Iter: 950, Training Loss: 1.632707953453064\n",
      "Iter: 1000, Training Loss: 1.655625343322754\n",
      "Iter: 1050, Training Loss: 1.6164946556091309\n",
      "Iter: 1100, Training Loss: 1.5438811779022217\n",
      "Iter: 1150, Training Loss: 1.5522816181182861\n",
      "Iter: 1200, Training Loss: 1.5702869892120361\n",
      "Iter: 1250, Training Loss: 1.4777531623840332\n",
      "Iter: 1300, Training Loss: 1.5196752548217773\n",
      "Iter: 1350, Training Loss: 1.5065381526947021\n",
      "Iter: 1400, Training Loss: 1.4629961252212524\n",
      "Iter: 1450, Training Loss: 1.458777666091919\n",
      "Iter: 1500, Training Loss: 1.4308786392211914\n",
      "Iter: 1550, Training Loss: 1.427152395248413\n",
      "Iter: 1600, Training Loss: 1.4109070301055908\n",
      "Iter: 1650, Training Loss: 1.392808198928833\n",
      "Iter: 1700, Training Loss: 1.3797428607940674\n",
      "Iter: 1750, Training Loss: 1.3801349401474\n",
      "Iter: 1800, Training Loss: 1.3961936235427856\n",
      "Iter: 1850, Training Loss: 1.3732385635375977\n",
      "Iter: 1900, Training Loss: 1.3724055290222168\n",
      "Iter: 1950, Training Loss: 1.341017246246338\n",
      "Iter: 2000, Training Loss: 1.3389027118682861\n",
      "Iter: 2050, Training Loss: 1.3876316547393799\n",
      "Iter: 2100, Training Loss: 1.3144445419311523\n",
      "Iter: 2150, Training Loss: 1.318798542022705\n",
      "Iter: 2200, Training Loss: 1.3406474590301514\n",
      "Iter: 2250, Training Loss: 1.2863566875457764\n",
      "Iter: 2300, Training Loss: 1.3099383115768433\n",
      "Iter: 2350, Training Loss: 1.2970647811889648\n",
      "Iter: 2400, Training Loss: 1.2620187997817993\n",
      "Iter: 2450, Training Loss: 1.2735611200332642\n",
      "Iter: 2500, Training Loss: 1.2709943056106567\n",
      "Iter: 2550, Training Loss: 1.2555065155029297\n",
      "Iter: 2600, Training Loss: 1.2546278238296509\n",
      "Iter: 2650, Training Loss: 1.2430214881896973\n",
      "Iter: 2700, Training Loss: 1.2605061531066895\n",
      "Iter: 2750, Training Loss: 1.2378895282745361\n",
      "Iter: 2800, Training Loss: 1.2485945224761963\n",
      "Iter: 2850, Training Loss: 1.230534315109253\n",
      "Iter: 2900, Training Loss: 1.2259254455566406\n",
      "Iter: 2950, Training Loss: 1.195204257965088\n",
      "Iter: 3000, Training Loss: 1.2282655239105225\n",
      "Iter: 3050, Training Loss: 1.2132843732833862\n",
      "Iter: 3100, Training Loss: 1.222975254058838\n",
      "Iter: 3150, Training Loss: 1.1940975189208984\n",
      "Iter: 3200, Training Loss: 1.2094919681549072\n",
      "Iter: 3250, Training Loss: 1.1720346212387085\n",
      "Iter: 3300, Training Loss: 1.1974363327026367\n",
      "Iter: 3350, Training Loss: 1.161831021308899\n",
      "Iter: 3400, Training Loss: 1.1671539545059204\n",
      "Iter: 3450, Training Loss: 1.1862136125564575\n",
      "Iter: 3500, Training Loss: 1.1189804077148438\n",
      "Iter: 3550, Training Loss: 1.1245300769805908\n",
      "Iter: 3600, Training Loss: 1.07310950756073\n",
      "Iter: 3650, Training Loss: 1.1029976606369019\n",
      "Iter: 3700, Training Loss: 1.1130354404449463\n",
      "Iter: 3750, Training Loss: 1.1306195259094238\n",
      "Iter: 3800, Training Loss: 1.1179914474487305\n",
      "Iter: 3850, Training Loss: 1.0933476686477661\n",
      "Iter: 3900, Training Loss: 1.079063892364502\n",
      "Iter: 3950, Training Loss: 1.0569052696228027\n",
      "Iter: 4000, Training Loss: 1.087354302406311\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "iteration = 0\n",
    "while True:\n",
    "    if iteration > max_iterations: break\n",
    "    x, y = get_next_batch(batch_size)\n",
    "    loss = train_gpt(x, y)\n",
    "    if iteration % 50 == 0:\n",
    "        print(f\"Iter: {iteration}, Training Loss: {loss}\")\n",
    "    \n",
    "    iteration += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "01c4b991",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as MultiHeadAttention_layer_call_fn, MultiHeadAttention_layer_call_and_return_conditional_losses, feedforward_layer_call_fn, feedforward_layer_call_and_return_conditional_losses, layer_normalization_13_layer_call_fn while saving (showing 5 of 432). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: gpt_trained/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: gpt_trained/assets\n"
     ]
    }
   ],
   "source": [
    "gpt.save('gpt_trained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b772cad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he day we long have looked for:\n",
      "I am your neighbour, and was suitor first.\n",
      "\n",
      "TRANIO:\n",
      "And I am one that love Bianca more\n",
      "Than words can witness, or your thoughts can guess.\n",
      "\n",
      "GREMIO:\n",
      "Youngling, thou canst not love so dear as I.\n",
      "\n",
      "TRANIO:\n",
      "Graybeard, thy love do\n"
     ]
    }
   ],
   "source": [
    "context, _ = get_next_batch(1, False)\n",
    "print(decoder(context[0].numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6f54f93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(context, max_generated_tokens):\n",
    "    \"\"\"\n",
    "        input : (B, T)\n",
    "    \n",
    "        B : Batch\n",
    "        T : Token\n",
    "    \"\"\"\n",
    "    print(decoder(context[0].numpy()), end='')\n",
    "    word_segment = ''\n",
    "    for _ in range(max_generated_tokens):\n",
    "        current_context = context[:, -context_length:] # Shape : (B, T)\n",
    "        logits = gpt(current_context) # Shape : (B, T, num_vocab)\n",
    "        # NOTE(Abid): We only care about the prediction of the last token\n",
    "        logits = logits[:, -1, :] # Shape : (B, 1, num_vocab)\n",
    "        # NOTE(Abid): It seems random.categorical requires logits, so no need for softmax here.\n",
    "        next_token = tf.random.categorical(tf.expand_dims(logits[0], axis=0), 1)\n",
    "        context = tf.concat([context, next_token], axis=1)\n",
    "        word_segment += decoder(next_token[0].numpy())\n",
    "        if next_token[0][0] == 1 or next_token[0][0] == 0:\n",
    "            print(word_segment, end='')\n",
    "            word_segment = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6d6224d8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he day we long have looked for:\n",
      "I am your neighbour, and was suitor first.\n",
      "\n",
      "TRANIO:\n",
      "And I am one that love Bianca more\n",
      "Than words can witness, or your thoughts can guess.\n",
      "\n",
      "GREMIO:\n",
      "Youngling, thou canst not love so dear as I.\n",
      "\n",
      "TRANIO:\n",
      "Graybeard, thy love down,--\n",
      "\n",
      "ROVERS:\n",
      "Those brother, my gracious boy:\n",
      "For, by his crown unto looking apt;\n",
      "And leason to grates it in me, I'll bear\n",
      "My cimissih'd to thee measure from whom;\n",
      "But do good from her with issue. My Leonte,\n",
      "It was for me. I most your news friends\n",
      "Hast accomplish'd to the courtesy,\n",
      "Would I lent but my wedded to destroy;\n",
      "So so I have bound whom I swear keeps\n",
      "Serving you for\n",
      "The counters, if you'r lace way, never York,\n",
      "Not doth deny, such as your guiders\n",
      "More past me, your pardon\n",
      "Give other twain, to spoir wearing,\n",
      "When sureon'd the seizes of sevented!\n",
      "\n",
      "Second Citizen:\n",
      "Once that, I know my name is a duty flesh:\n",
      "'Tis virtue way\n",
      "I'ld not by make melaces. I pray you,\n",
      "I the wretches not so so shrill.\n",
      "\n",
      "Nurse:\n",
      "The queen shrews: let's not that I move,--\n",
      "Hadhest--love't with thy bears.\n",
      "\n",
      "SICINIUS:\n",
      "Nor now, for the good Margaret's curse;\n",
      "That my name is nature, so not determine'd\n",
      "Offer, the need nor skins.\n",
      "But nor our city's I'll gold and you nor he;\n",
      "And see, besides, what once would Clarence,\n"
     ]
    }
   ],
   "source": [
    "generate_text(context, 1_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17ab34be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.11.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1e7084",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
