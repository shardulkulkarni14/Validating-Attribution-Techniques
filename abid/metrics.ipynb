{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2beef11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85530fd4",
   "metadata": {},
   "source": [
    "# Metrics Hub\n",
    "This will serve as the main hub for adding metrics that will go into the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06231ca",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddf0274e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "from skimage import img_as_float\n",
    "from skimage import exposure\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772a07e1",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31c495db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def normalize(x, method='standard', axis=None):\n",
    "    '''Normalizes the input with specified method.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : array-like\n",
    "    method : string, optional\n",
    "        Valid values for method are:\n",
    "        - 'standard': mean=0, std=1\n",
    "        - 'range': min=0, max=1\n",
    "        - 'sum': sum=1\n",
    "    axis : int, optional\n",
    "        Axis perpendicular to which array is sliced and normalized.\n",
    "        If None, array is flattened and normalized.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    res : numpy.ndarray\n",
    "        Normalized array.\n",
    "    '''\n",
    "    # TODO: Prevent divided by zero if the map is flat\n",
    "    x = np.array(x, copy=False)\n",
    "    if axis is not None:\n",
    "        y = np.rollaxis(x, axis).reshape([x.shape[axis], -1])\n",
    "        shape = np.ones(len(x.shape))\n",
    "        shape[axis] = x.shape[axis]\n",
    "        if method == 'standard':\n",
    "            res = (x - np.mean(y, axis=1).reshape(shape)) / np.std(y, axis=1).reshape(shape)\n",
    "        elif method == 'range':\n",
    "            res = (x - np.min(y, axis=1).reshape(shape)) / (np.max(y, axis=1) - np.min(y, axis=1)).reshape(shape)\n",
    "        elif method == 'sum':\n",
    "            res = x / np.float_(np.sum(y, axis=1).reshape(shape))\n",
    "        else:\n",
    "            raise ValueError('method not in {\"standard\", \"range\", \"sum\"}')\n",
    "    else:\n",
    "        if method == 'standard':\n",
    "            res = (x - np.mean(x)) / np.std(x)\n",
    "        elif method == 'range':\n",
    "            res = (x - np.min(x)) / (np.max(x) - np.min(x))\n",
    "        elif method == 'sum':\n",
    "            res = x / float(np.sum(x))\n",
    "        else:\n",
    "            raise ValueError('method not in {\"standard\", \"range\", \"sum\"}')\n",
    "    return res\n",
    "\n",
    "\n",
    "def match_hist(image, cdf, bin_centers, nbins=256):\n",
    "    '''Modify pixels of input image so that its histogram matches target image histogram, specified by:\n",
    "    cdf, bin_centers = cumulative_distribution(target_image)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image : array\n",
    "        Image to be transformed.\n",
    "    cdf : 1D array\n",
    "        Values of cumulative distribution function of the target histogram.\n",
    "    bin_centers ; 1D array\n",
    "        Centers of bins of the target histogram.\n",
    "    nbins : int, optional\n",
    "        Number of bins for image histogram.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    out : float array\n",
    "        Image array after histogram matching.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    [1] Matlab implementation histoMatch(MTX, N, X) by Simoncelli, 7/96.\n",
    "    '''\n",
    "    image = img_as_float(image)\n",
    "    old_cdf, old_bin = exposure.cumulative_distribution(image, nbins) # Unlike [1], we didn't add small positive number to the histogram\n",
    "    new_bin = np.interp(old_cdf, cdf, bin_centers)\n",
    "    out = np.interp(image.ravel(), old_bin, new_bin)\n",
    "    return out.reshape(image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0a8226",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# Metrics start here..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5f12c9",
   "metadata": {},
   "source": [
    "### 1. (Similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aceef7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def SIM(saliency_map1, saliency_map2):\n",
    "    '''\n",
    "    Similarity between two different saliency maps when viewed as distributions\n",
    "    (SIM=1 means the distributions are identical).\n",
    "\n",
    "    This similarity measure is also called **histogram intersection**.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    saliency_map1 : real-valued matrix\n",
    "        If the two maps are different in shape, saliency_map1 will be resized to match saliency_map2.\n",
    "    saliency_map2 : real-valued matrix\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    SIM : float, between [0,1]\n",
    "    '''\n",
    "    map1 = np.array(saliency_map1, copy=False)\n",
    "    map2 = np.array(saliency_map2, copy=False)\n",
    "    if map1.shape != map2.shape:\n",
    "        map1 = resize(map1, map2.shape, order=3) # bi-cubic/nearest is what Matlab imresize() does by default\n",
    "    # Normalize the two maps to have values between [0,1] and sum up to 1\n",
    "    map1 = normalize(map1, method='range')\n",
    "    map2 = normalize(map2, method='range')\n",
    "    map1 = normalize(map1, method='sum')\n",
    "    map2 = normalize(map2, method='sum')\n",
    "    # Compute histogram intersection\n",
    "    intersection = np.minimum(map1, map2)\n",
    "    return np.sum(intersection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849f1417",
   "metadata": {},
   "source": [
    "### 2.  Pearson's Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d29314c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def CC(saliency_map1, saliency_map2):\n",
    "    '''\n",
    "    Pearson's correlation coefficient between two different saliency maps\n",
    "    (CC=0 for uncorrelated maps, CC=1 for perfect linear correlation).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    saliency_map1 : real-valued matrix\n",
    "        If the two maps are different in shape, saliency_map1 will be resized to match saliency_map2.\n",
    "    saliency_map2 : real-valued matrix\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    CC : float, between [-1,1]\n",
    "    '''\n",
    "    map1 = np.array(saliency_map1, copy=False)\n",
    "    map2 = np.array(saliency_map2, copy=False)\n",
    "    if map1.shape != map2.shape:\n",
    "        map1 = resize(map1, map2.shape, order=3) # bi-cubic/nearest is what Matlab imresize() does by default\n",
    "    # Normalize the two maps to have zero mean and unit std\n",
    "    map1 = normalize(map1, method='standard')\n",
    "    map2 = normalize(map2, method='standard')\n",
    "    # Compute correlation coefficient\n",
    "    return np.corrcoef(map1.ravel(), map2.ravel())[0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128c472c",
   "metadata": {},
   "source": [
    "### 3. Normalized Scanpath Saliency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d835124",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def NSS(saliency_map, fixation_map):\n",
    "    '''\n",
    "    Normalized scanpath saliency of a saliency map,\n",
    "    defined as the mean value of normalized (i.e., standardized) saliency map at fixation locations.\n",
    "    You can think of it as a z-score. (Larger value implies better performance.)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    saliency_map : real-valued matrix\n",
    "        If the two maps are different in shape, saliency_map will be resized to match fixation_map..\n",
    "    fixation_map : binary matrix\n",
    "        Human fixation map (1 for fixated location, 0 for elsewhere).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    NSS : float, positive\n",
    "    '''\n",
    "    s_map = np.array(saliency_map, copy=False)\n",
    "    f_map = np.array(fixation_map, copy=False) > 0.5\n",
    "    if s_map.shape != f_map.shape:\n",
    "        s_map = resize(s_map, f_map.shape)\n",
    "    # Normalize saliency map to have zero mean and unit std\n",
    "    s_map = normalize(s_map, method='standard')\n",
    "    # Mean saliency value at fixation locations\n",
    "    return np.mean(s_map[f_map])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0698a98",
   "metadata": {},
   "source": [
    "### 4. Area Under ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a82dcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def AUC_Judd(saliency_map, fixation_map, jitter=True):\n",
    "    '''\n",
    "    AUC stands for Area Under ROC Curve.\n",
    "    This measures how well the saliency map of an image predicts the ground truth human fixations on the image.\n",
    "\n",
    "    ROC curve is created by sweeping through threshold values\n",
    "    determined by range of saliency map values at fixation locations.\n",
    "    True positive (tp) rate correspond to the ratio of saliency map values above threshold\n",
    "    at fixation locations to the total number of fixation locations.\n",
    "    False positive (fp) rate correspond to the ratio of saliency map values above threshold\n",
    "    at all other locations to the total number of possible other locations (non-fixated image pixels).\n",
    "\n",
    "    AUC=0.5 is chance level.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    saliency_map : real-valued matrix\n",
    "    fixation_map : binary matrix\n",
    "        Human fixation map.\n",
    "    jitter : boolean, optional\n",
    "        If True (default), a small random number would be added to each pixel of the saliency map.\n",
    "        Jitter saliency maps that come from saliency models that have a lot of zero values.\n",
    "        If the saliency map is made with a Gaussian then it does not need to be jittered\n",
    "        as the values vary and there is not a large patch of the same value.\n",
    "        In fact, jittering breaks the ordering in the small values!\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    AUC : float, between [0,1]\n",
    "    '''\n",
    "    saliency_map = np.array(saliency_map, copy=False)\n",
    "    fixation_map = np.array(fixation_map, copy=False) > 0.5\n",
    "    # If there are no fixation to predict, return NaN\n",
    "    if not np.any(fixation_map):\n",
    "        print('no fixation to predict')\n",
    "        return np.nan\n",
    "    # Make the saliency_map the size of the fixation_map\n",
    "    if saliency_map.shape != fixation_map.shape:\n",
    "        saliency_map = resize(saliency_map, fixation_map.shape, order=3)\n",
    "    # Jitter the saliency map slightly to disrupt ties of the same saliency value\n",
    "    if jitter:\n",
    "        saliency_map += random.rand(*saliency_map.shape) * 1e-7\n",
    "    # Normalize saliency map to have values between [0,1]\n",
    "    saliency_map = normalize(saliency_map, method='range')\n",
    "\n",
    "    S = saliency_map.ravel()\n",
    "    F = fixation_map.ravel()\n",
    "    S_fix = S[F] # Saliency map values at fixation locations\n",
    "    n_fix = len(S_fix)\n",
    "    n_pixels = len(S)\n",
    "    # Calculate AUC\n",
    "    thresholds = sorted(S_fix, reverse=True)\n",
    "    tp = np.zeros(len(thresholds)+2)\n",
    "    fp = np.zeros(len(thresholds)+2)\n",
    "    tp[0] = 0; tp[-1] = 1\n",
    "    fp[0] = 0; fp[-1] = 1\n",
    "    for k, thresh in enumerate(thresholds):\n",
    "        above_th = np.sum(S >= thresh) # Total number of saliency map values above threshold\n",
    "        tp[k+1] = (k + 1) / float(n_fix) # Ratio saliency map values at fixation locations above threshold\n",
    "        fp[k+1] = (above_th - k - 1) / float(n_pixels - n_fix) # Ratio other saliency map values above threshold\n",
    "    return np.trapz(tp, fp) # y, x\n",
    "\n",
    "\n",
    "def AUC_Borji(saliency_map, fixation_map, n_rep=100, step_size=0.1, rand_sampler=None):\n",
    "    '''\n",
    "    This measures how well the saliency map of an image predicts the ground truth human fixations on the image.\n",
    "\n",
    "    ROC curve created by sweeping through threshold values at fixed step size\n",
    "    until the maximum saliency map value.\n",
    "    True positive (tp) rate correspond to the ratio of saliency map values above threshold\n",
    "    at fixation locations to the total number of fixation locations.\n",
    "    False positive (fp) rate correspond to the ratio of saliency map values above threshold\n",
    "    at random locations to the total number of random locations\n",
    "    (as many random locations as fixations, sampled uniformly from fixation_map ALL IMAGE PIXELS),\n",
    "    averaging over n_rep number of selections of random locations.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    saliency_map : real-valued matrix\n",
    "    fixation_map : binary matrix\n",
    "        Human fixation map.\n",
    "    n_rep : int, optional\n",
    "        Number of repeats for random sampling of non-fixated locations.\n",
    "    step_size : int, optional\n",
    "        Step size for sweeping through saliency map.\n",
    "    rand_sampler : callable\n",
    "        S_rand = rand_sampler(S, F, n_rep, n_fix)\n",
    "        Sample the saliency map at random locations to estimate false positive.\n",
    "        Return the sampled saliency values, S_rand.shape=(n_fix,n_rep)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    AUC : float, between [0,1]\n",
    "    '''\n",
    "    saliency_map = np.array(saliency_map, copy=False)\n",
    "    fixation_map = np.array(fixation_map, copy=False) > 0.5\n",
    "    # If there are no fixation to predict, return NaN\n",
    "    if not np.any(fixation_map):\n",
    "        print('no fixation to predict')\n",
    "        return np.nan\n",
    "    # Make the saliency_map the size of the fixation_map\n",
    "    if saliency_map.shape != fixation_map.shape:\n",
    "        saliency_map = resize(saliency_map, fixation_map.shape, order=3)\n",
    "    # Normalize saliency map to have values between [0,1]\n",
    "    saliency_map = normalize(saliency_map, method='range')\n",
    "\n",
    "    S = saliency_map.ravel()\n",
    "    F = fixation_map.ravel()\n",
    "    S_fix = S[F] # Saliency map values at fixation locations\n",
    "    n_fix = len(S_fix)\n",
    "    n_pixels = len(S)\n",
    "    # For each fixation, sample n_rep values from anywhere on the saliency map\n",
    "    if rand_sampler is None:\n",
    "        r = random.randint(0, n_pixels, [n_fix, n_rep])\n",
    "        S_rand = S[r] # Saliency map values at random locations (including fixated locations!? underestimated)\n",
    "    else:\n",
    "        S_rand = rand_sampler(S, F, n_rep, n_fix)\n",
    "    # Calculate AUC per random split (set of random locations)\n",
    "    auc = np.zeros(n_rep) * np.nan\n",
    "    for rep in range(n_rep):\n",
    "        thresholds = np.r_[0:np.max(np.r_[S_fix, S_rand[:,rep]]):step_size][::-1]\n",
    "        tp = np.zeros(len(thresholds)+2)\n",
    "        fp = np.zeros(len(thresholds)+2)\n",
    "        tp[0] = 0; tp[-1] = 1\n",
    "        fp[0] = 0; fp[-1] = 1\n",
    "        for k, thresh in enumerate(thresholds):\n",
    "            tp[k+1] = np.sum(S_fix >= thresh) / float(n_fix)\n",
    "            fp[k+1] = np.sum(S_rand[:,rep] >= thresh) / float(n_fix)\n",
    "        auc[rep] = np.trapz(tp, fp)\n",
    "    return np.mean(auc) # Average across random splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a417cf",
   "metadata": {},
   "source": [
    "### 5. Wasserstein Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d769547",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def wasserstein_distance(cam, perturbed_cam):\n",
    "    saliency_map1 = np.array(cam.reshape(90000))\n",
    "    saliency_map2 = np.array(perturbed_cam.reshape(90000))\n",
    "    emd = sci.wasserstein_distance(saliency_map1, saliency_map2) \n",
    "    return emd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed420023",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Calling all Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e87abef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def calculate_metrics(cam, perturbed_cam):\n",
    "    sim = SIM(cam, perturbed_cam)\n",
    "    cc = CC(cam, perturbed_cam)\n",
    "    nss = NSS(cam, perturbed_cam)\n",
    "    auc_judd = AUC_Judd(cam, perturbed_cam)\n",
    "    auc_borji = AUC_Borji(cam, perturbed_cam)\n",
    "    emd = wasserstein_distance(cam, perturbed_cam)\n",
    "    return sim, cc, nss, auc_judd, auc_borji, emd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "daf58878",
   "metadata": {},
   "outputs": [
    {
     "ename": "InterpolationMissingOptionError",
     "evalue": "Bad value substitution: option 'lib_name' in section 'DEFAULT' contains an interpolation key 'repo' which is not a valid option name. Raw value: '%(repo)s'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInterpolationMissingOptionError\u001b[0m           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#| hide\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnbdev\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mnbdev\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnbdev_export\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetrics.ipynb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m;\n",
      "File \u001b[0;32m/scratch/hashimi/python/lib/python3.8/site-packages/fastcore/script.py:110\u001b[0m, in \u001b[0;36mcall_parse.<locals>._f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_f\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    109\u001b[0m     mod \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39mgetmodule(inspect\u001b[38;5;241m.\u001b[39mcurrentframe()\u001b[38;5;241m.\u001b[39mf_back)\n\u001b[0;32m--> 110\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mod: \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m SCRIPT_INFO\u001b[38;5;241m.\u001b[39mfunc \u001b[38;5;129;01mand\u001b[39;00m mod\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m: SCRIPT_INFO\u001b[38;5;241m.\u001b[39mfunc \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(sys\u001b[38;5;241m.\u001b[39margv)\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m sys\u001b[38;5;241m.\u001b[39margv[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m: sys\u001b[38;5;241m.\u001b[39margv\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/scratch/hashimi/python/lib/python3.8/site-packages/nbdev/doclinks.py:140\u001b[0m, in \u001b[0;36mnbdev_export\u001b[0;34m(path, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m files: nb_export(f)\n\u001b[1;32m    139\u001b[0m add_init(get_config()\u001b[38;5;241m.\u001b[39mlib_path)\n\u001b[0;32m--> 140\u001b[0m \u001b[43m_build_modidx\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/hashimi/python/lib/python3.8/site-packages/nbdev/doclinks.py:98\u001b[0m, in \u001b[0;36m_build_modidx\u001b[0;34m(dest, nbs_path, skip_exists)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m idxfile\u001b[38;5;241m.\u001b[39mexists(): res \u001b[38;5;241m=\u001b[39m exec_local(idxfile\u001b[38;5;241m.\u001b[39mread_text(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(syms\u001b[38;5;241m=\u001b[39m{}, settings\u001b[38;5;241m=\u001b[39m{}) \n\u001b[0;32m---> 98\u001b[0m res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msettings\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m {k:v \u001b[38;5;28;01mfor\u001b[39;00m k,v \u001b[38;5;129;01min\u001b[39;00m get_config()\u001b[38;5;241m.\u001b[39md\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m     99\u001b[0m                    \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdoc_host\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdoc_baseurl\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlib_path\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgit_url\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbranch\u001b[39m\u001b[38;5;124m'\u001b[39m)}\n\u001b[1;32m    100\u001b[0m code_root \u001b[38;5;241m=\u001b[39m dest\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mresolve()\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m globtastic(dest, file_glob\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*.py\u001b[39m\u001b[38;5;124m\"\u001b[39m, skip_file_re\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m^_\u001b[39m\u001b[38;5;124m'\u001b[39m, skip_folder_re\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m.ipynb_checkpoints\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/scratch/hashimi/python/lib/python3.8/site-packages/nbdev/doclinks.py:98\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m idxfile\u001b[38;5;241m.\u001b[39mexists(): res \u001b[38;5;241m=\u001b[39m exec_local(idxfile\u001b[38;5;241m.\u001b[39mread_text(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(syms\u001b[38;5;241m=\u001b[39m{}, settings\u001b[38;5;241m=\u001b[39m{}) \n\u001b[0;32m---> 98\u001b[0m res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msettings\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m {k:v \u001b[38;5;28;01mfor\u001b[39;00m k,v \u001b[38;5;129;01min\u001b[39;00m get_config()\u001b[38;5;241m.\u001b[39md\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m     99\u001b[0m                    \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdoc_host\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdoc_baseurl\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlib_path\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgit_url\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbranch\u001b[39m\u001b[38;5;124m'\u001b[39m)}\n\u001b[1;32m    100\u001b[0m code_root \u001b[38;5;241m=\u001b[39m dest\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mresolve()\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m globtastic(dest, file_glob\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*.py\u001b[39m\u001b[38;5;124m\"\u001b[39m, skip_file_re\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m^_\u001b[39m\u001b[38;5;124m'\u001b[39m, skip_folder_re\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m.ipynb_checkpoints\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/usr/lib/python3.8/_collections_abc.py:744\u001b[0m, in \u001b[0;36mItemsView.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    742\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    743\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mapping:\n\u001b[0;32m--> 744\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m (key, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m)\n",
      "File \u001b[0;32m/usr/lib/python3.8/configparser.py:1255\u001b[0m, in \u001b[0;36mSectionProxy.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1253\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parser\u001b[38;5;241m.\u001b[39mhas_option(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, key):\n\u001b[1;32m   1254\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[0;32m-> 1255\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.8/configparser.py:799\u001b[0m, in \u001b[0;36mRawConfigParser.get\u001b[0;34m(self, section, option, raw, vars, fallback)\u001b[0m\n\u001b[1;32m    797\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m value\n\u001b[1;32m    798\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 799\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpolation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbefore_get\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moption\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.8/configparser.py:395\u001b[0m, in \u001b[0;36mBasicInterpolation.before_get\u001b[0;34m(self, parser, section, option, value, defaults)\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbefore_get\u001b[39m(\u001b[38;5;28mself\u001b[39m, parser, section, option, value, defaults):\n\u001b[1;32m    394\u001b[0m     L \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 395\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpolate_some\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moption\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefaults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(L)\n",
      "File \u001b[0;32m/usr/lib/python3.8/configparser.py:434\u001b[0m, in \u001b[0;36mBasicInterpolation._interpolate_some\u001b[0;34m(self, parser, option, accum, rest, section, map, depth)\u001b[0m\n\u001b[1;32m    432\u001b[0m     v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m[var]\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m--> 434\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InterpolationMissingOptionError(\n\u001b[1;32m    435\u001b[0m         option, section, rawval, var) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m v:\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpolate_some(parser, option, accum, v,\n\u001b[1;32m    438\u001b[0m                            section, \u001b[38;5;28mmap\u001b[39m, depth \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mInterpolationMissingOptionError\u001b[0m: Bad value substitution: option 'lib_name' in section 'DEFAULT' contains an interpolation key 'repo' which is not a valid option name. Raw value: '%(repo)s'"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "import nbdev\n",
    "nbdev.nbdev_export(\"metrics.ipynb\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d604199",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
