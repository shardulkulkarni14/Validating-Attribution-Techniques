{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "030a4235-3b5f-4910-9861-af03da9742b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/project/validating_attribution_techniques/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bd2ac03-8454-4fbf-938a-801057b998a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Nov  5 01:05:54 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.86.10              Driver Version: 535.86.10    CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 2080 Ti     Off | 00000000:B1:00.0 Off |                  N/A |\n",
      "| 33%   57C    P2              81W / 250W |    807MiB / 11264MiB |     37%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce RTX 2080 Ti     Off | 00000000:B2:00.0 Off |                  N/A |\n",
      "| 22%   25C    P8               1W / 250W |      3MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA GeForce RTX 2080 Ti     Off | 00000000:DA:00.0 Off |                  N/A |\n",
      "| 22%   24C    P8              16W / 250W |   8021MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA GeForce RTX 2080 Ti     Off | 00000000:DB:00.0 Off |                  N/A |\n",
      "| 22%   24C    P8              21W / 250W |      3MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46cb482a-b075-4f41-9fb4-24c40cc910fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from commons.api.utils import set_to_our_gpus, enable_web_access\n",
    "set_to_our_gpus(\"1\")\n",
    "enable_web_access()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82f5a5cc-0d66-430b-9c98-9f0879540f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from commons.api.imagenet_tiny import get_imagenet_classes, get_random_images\n",
    "\n",
    "# from shardul.ScoreCAM.cam import CAM, GradCAM, GradCAMpp, SmoothGradCAMpp, ScoreCAM\n",
    "from torchvision.models import resnet50, resnet18, vgg16, inception_v3\n",
    "from torchvision.models.inception import Inception3\n",
    "\n",
    "\n",
    "from shardul.api.viz import visualize_saliency_overlay\n",
    "from commons.api.imagenet_tiny import get_imagenet_classes, get_random_images\n",
    "\n",
    "\n",
    "from commons.api.method.attribution import attribution\n",
    "\n",
    "\n",
    "from commons.api.metric.compare_metrics import normalize, match_hist, normalize_map\n",
    "from commons.api.metric.compare_metrics import SIM, CC, NSS, AUC_Judd, wasserstein_distance\n",
    "from commons.api.metric.compare_metrics import calculate_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f1ca4ea-bdf7-4c60-b7bc-e2502f7a0128",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/project/validating_attribution_techniques/torchCAM\")\n",
    "from torchcam.methods.gradient import SmoothGradCAMpp, GradCAMpp, GradCAM, LayerCAM\n",
    "from torchcam.methods.activation import ScoreCAM\n",
    "from torchcam.utils import overlay_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc21769e-7e8c-428e-9a7e-d8d5cd76ed5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/project/validating_attribution_techniques/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0d98841-481d-4c62-b1a3-7712df9fa94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.figure import Figure\n",
    "from io import BytesIO\n",
    "from matplotlib.transforms import IdentityTransform\n",
    "\n",
    "from PIL import Image\n",
    "from numpy import random\n",
    "import json\n",
    "# import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.transform\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from scipy.spatial.distance import cdist\n",
    "from cv2 import EMD\n",
    "from captum.attr import LayerAttribution, LayerGradCam\n",
    "import cv2\n",
    "from torchvision.io.image import read_image\n",
    "from torchvision.transforms.functional import normalize, resize, to_pil_image \n",
    "# from ScoreCAM import cam\n",
    "\n",
    "from PIL import Image\n",
    "from matplotlib.pyplot import imshow\n",
    "from torchvision import models, transforms\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c22ee5c-fd87-4466-aae5-9ab93438c73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def text_to_rgba(s, *, dpi, **kwargs):\n",
    "    # To convert a text string to an image, we can:\n",
    "    # - draw it on an empty and transparent figure;\n",
    "    # - save the figure to a temporary buffer using ``bbox_inches=\"tight\",\n",
    "    #   pad_inches=0`` which will pick the correct area to save;\n",
    "    # - load the buffer using ``plt.imread``.\n",
    "    #\n",
    "    # (If desired, one can also directly save the image to the filesystem.)\n",
    "    fig = Figure(facecolor=\"none\", figsize=(10, 10))\n",
    "    fig.text(0, 0, s, **kwargs)\n",
    "    with BytesIO() as buf:\n",
    "        fig.savefig(buf, dpi=dpi, format=\"png\", bbox_inches=\"tight\",\n",
    "                    pad_inches=0)\n",
    "        buf.seek(0)\n",
    "        rgba = plt.imread(buf)\n",
    "    return rgba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8a55766-8aa2-43da-a4ba-417b9e1aead4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_patch(image, top_left_x, top_left_y, patch_size):\n",
    "    patched_image = np.copy(image)\n",
    "    patched_image[top_left_y : top_left_y+patch_size,\n",
    "                  top_left_x : top_left_x+patch_size, :] = 0\n",
    "    return patched_image\n",
    "def generate_img_occlusion_list(img, saliency, patch_size, saliency_reduce_func=np.mean):\n",
    "    occlusion_img_list = []\n",
    "    occlusion_saliency_statistic = []\n",
    "    saliency = np.array(Image.fromarray(saliency).resize(img.shape[0], img.shape[1]))\n",
    "    \n",
    "    for top_left_y in range(0, img.shape[1], patch_size):\n",
    "        for top_left_x in range(0, img.shape[0], patch_size):\n",
    "            patched_image = apply_patch(img, top_left_x, top_left_y, patch_size).astype('float32') / 255.0\n",
    "            occlusion_img_list.append(patched_image)\n",
    "            occlusion_saliency_statistic.append(saliency_reduce_func(saliency[top_left_y : top_left_y+patch_size,\n",
    "                                                                              top_left_x : top_left_x+patch_size]))\n",
    "            \n",
    "    return np.array(occlusion_img_list), np.array(occlusion_saliency_statistic)\n",
    "def generate_img_occlusion_list_no_saliency(img, patch_size):\n",
    "    occlusion_img_list = []\n",
    "    occlusion_saliency_statistic = []\n",
    "    \n",
    "    for top_left_y in range(0, img.shape[1], patch_size):\n",
    "        for top_left_x in range(0, img.shape[0], patch_size):\n",
    "            patched_image = apply_patch(img, top_left_x, top_left_y, patch_size).astype('float32') / 255.0\n",
    "            occlusion_img_list.append(patched_image)\n",
    "            \n",
    "    return np.array(occlusion_img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff6d911d-35b4-47d3-a469-6b0b0f065cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = get_imagenet_classes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95697cb5-dfef-4b9f-9417-58490c7c9446",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load all images\n",
    "images = np.load('/project/validating_attribution_techniques/abid/data/ground_saliency_images/images_2_fixed.npy', allow_pickle=True)\n",
    "masks = np.load('/project/validating_attribution_techniques/abid/data/ground_saliency_images/obj_masks_2_fixed.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c957830b-8b40-44f0-a705-0999189bdbc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/shkulkar/python/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/scratch/shkulkar/python/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/scratch/shkulkar/python/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Inception3(\n",
       "  (Conv2d_1a_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_2a_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_2b_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (Conv2d_3b_1x1): BasicConv2d(\n",
       "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_4a_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (Mixed_5b): InceptionA(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_2): BasicConv2d(\n",
       "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_5c): InceptionA(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_2): BasicConv2d(\n",
       "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_5d): InceptionA(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_2): BasicConv2d(\n",
       "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6a): InceptionB(\n",
       "    (branch3x3): BasicConv2d(\n",
       "      (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6b): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6c): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6d): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6e): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (AuxLogits): InceptionAux(\n",
       "    (conv0): BasicConv2d(\n",
       "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv1): BasicConv2d(\n",
       "      (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (fc): Linear(in_features=768, out_features=1000, bias=True)\n",
       "  )\n",
       "  (Mixed_7a): InceptionD(\n",
       "    (branch3x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_3): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_4): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_7b): InceptionE(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_7c): InceptionE(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_cuda = True\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "model_resnet50 = resnet50(pretrained=True).to(device).eval()\n",
    "# model_resnet18 = resnet18(pretrained=True).to(device).eval()\n",
    "# model_vgg = vgg16(pretrained=True).to(device).eval()\n",
    "model_inception3 = inception_v3(pretrained=True).to(device).eval()\n",
    "model_inception3.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "070c8dfc-7233-418e-9890-25cb6c6efd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_layer = model_resnet50.layer3[-1]\n",
    "target_layer = model_resnet50.layer4[-1]\n",
    "\n",
    "target_layer_inception = model_inception3.Mixed_7c.branch3x3dbl_3b\n",
    "# target_layer_index = 28\n",
    "# target_layer_vgg = \"features.24\"\n",
    "# target_layer_vgg = model_vgg.features[target_layer_index]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25dde1be-8854-4365-8391-31ddd95c0408",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_layer_inception\n",
    "# target_layer_vgg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc0bd2d-1227-4c31-8a15-4d97479f3706",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d037867d-61ae-40e0-8258-075b6ffc4acd",
   "metadata": {},
   "source": [
    "# Inter Model - ResNet50 - ResnNet18 Vs Vgg16 vs InceptionV3\n",
    "- ResNet50 is base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d13faa-28b9-4b1c-b4b6-7b6b80d92420",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_metrics_values(techniques, metrics):\n",
    "    metrics_values = {}\n",
    "    for technique in techniques:\n",
    "        metrics_values[technique] = {}\n",
    "        for metric in metrics:\n",
    "            metrics_values[technique][metric] = []\n",
    "    return metrics_values\n",
    "\n",
    "metrics_values = {\n",
    "    \"GradCAM\": {\n",
    "        \"sim\": [],\n",
    "        \"cc\": [],\n",
    "        \"nss\": [],\n",
    "        \"auc\": [],\n",
    "        \"emd\": [],\n",
    "        \"ior\": []\n",
    "    },\n",
    "    \"ScoreCAM\": {\n",
    "        \"sim\": [],\n",
    "        \"cc\": [],\n",
    "        \"nss\": [],\n",
    "        \"auc\": [],\n",
    "        \"emd\": [],\n",
    "        \"ior\": []\n",
    "    },\n",
    "    \"LayerCAM\": {\n",
    "        \"sim\": [],\n",
    "        \"cc\": [],\n",
    "        \"nss\": [],\n",
    "        \"auc\": [],\n",
    "        \"emd\": [],\n",
    "        \"ior\": []\n",
    "    },\n",
    "    \"SmoothGradCAMpp\": {\n",
    "        \"sim\": [],\n",
    "        \"cc\": [],\n",
    "        \"nss\": [],\n",
    "        \"auc\": [],\n",
    "        \"emd\": [],\n",
    "        \"ior\": []\n",
    "    }\n",
    "}\n",
    "\n",
    "# Define the techniques and metrics you want to collect\n",
    "techniques = [\"GradCAM\", \"ScoreCAM\", \"SmoothGradCAMpp\", \"LayerCAM\"]\n",
    "metrics = [\"sim\", \"cc\", \"nss\", \"auc\", \"emd\", \"ior\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcca1da6-11de-4d18-a814-fc35417c1dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = [i for i in range(0, 61)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683e9273-ed9a-4a96-a0be-0b7a4c492207",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"ResNet18\", \"VGG16\", \"InceptionV3\"]\n",
    "# indexes = [0, 1]\n",
    "# img_idx = 0\n",
    "\n",
    "for img_idx in indexes:\n",
    "    print(f\"Iteration, {img_idx}\")\n",
    "    gradcam = np.array([])\n",
    "    scorecam = np.array([])\n",
    "    smoothgradcampp = np.array([])\n",
    "    layercam = np.array([])\n",
    "    original_image = Image.fromarray(images[img_idx])\n",
    "    imshow(original_image)\n",
    "    input_tensor = transform(original_image).to(device)\n",
    "    mask = masks[img_idx]\n",
    "    #if in case you do not want to specify target layer(default is set to 'layer4')\n",
    "    grad_cam, grad_idx, grad_probs = attribution(model_resnet50, input_tensor, \"GradCAM\", target_layer)\n",
    "    score_cam, score_idx, score_probs = attribution(model_resnet50, input_tensor, \"ScoreCAM\", target_layer)   \n",
    "    smoothgradpp_cam, smoothgradpp_idx, smoothgradpp_probs = attribution(model_resnet50, input_tensor, \"SmoothGradCAMpp\", target_layer)\n",
    "    layer_cam, layer_idx, layer_probs = attribution(model_resnet50, input_tensor, \"LayerCAM\", target_layer)\n",
    "    # fig, axes = plt.subplots(ncols=2, nrows=1)\n",
    "    fig, axes = plt.subplots(ncols=4, nrows=1)\n",
    "    \n",
    "    fig.set_figwidth(12)\n",
    "    fig.set_layout_engine('tight')\n",
    "    fig.suptitle(\"Attribution Techniques\", fontsize=16, fontweight=\"bold\",y=0.9)\n",
    "    # fig.set_figheight(40)\n",
    "    # Turn off the axis for each subplot\n",
    "    for ax in axes:\n",
    "        ax.axis('off')\n",
    "    # Titles for each subplot\n",
    "    titles = [ \"GradCAM\", \"ScoreCAM\", \"SmoothGradCAMpp\", \"LayerCAM\"]\n",
    "    \n",
    "    visualize_saliency_overlay(axes[0], original_image, grad_cam, grad_probs, grad_idx, classes);\n",
    "    visualize_saliency_overlay(axes[1], original_image, score_cam, score_probs, score_idx, classes);\n",
    "    visualize_saliency_overlay(axes[2], original_image, smoothgradpp_cam, smoothgradpp_probs, smoothgradpp_idx, classes);\n",
    "    visualize_saliency_overlay(axes[3], original_image, layer_cam, layer_probs, layer_idx, classes);\n",
    "    for i, ax in enumerate(axes):\n",
    "        ax.text(0.5, -0.1, titles[i], horizontalalignment='center', fontsize=12, fontweight='bold', transform=ax.transAxes)\n",
    "    fig.savefig(f\"/project/validating_attribution_techniques/shardul/data/Doc/Experimentation/Inter_Model/InceptionV3/Img_{img_idx}/Results/Ground_truth_{img_idx}.png\")\n",
    "    plt.close(fig)\n",
    "    pertubed_grad_cam, pertubed_grad_idx, pertubed_grad_probs = attribution(model_inception3, input_tensor, \"GradCAM\", target_layer_inception)\n",
    "    pertubed_score_cam, pertubed_score_idx, pertubed_score_probs = attribution(model_inception3, input_tensor, \"ScoreCAM\", target_layer_inception)   \n",
    "    pertubed_smoothgradpp_cam, pertubed_smoothgradpp_idx, pertubed_smoothgradpp_probs = attribution(model_inception3, input_tensor, \"SmoothGradCAMpp\", target_layer_inception)\n",
    "    pertubed_layer_cam, pertubed_layer_idx, pertubed_layer_probs = attribution(model_inception3, input_tensor, \"LayerCAM\", target_layer_inception)\n",
    "\n",
    "    \n",
    "    fig, axes = plt.subplots(ncols=8, nrows=2)\n",
    "    fig.suptitle(\"ResNet50 Vs InceptionV3\", fontsize=16, fontweight='bold', x=0.5)\n",
    "    # Iterate through axes and turn off the axes for each subplot\n",
    "    for row in axes:\n",
    "        for ax in row:\n",
    "            ax.axis('off')\n",
    "\n",
    "    for col in [0, 2, 4, 6]:\n",
    "        # Add the title at the bottom of the image in the second row\n",
    "        title = titles[col // 2]\n",
    "        axes[1, col].text(0.5, -0.12, title, horizontalalignment='center', fontsize=12, fontweight='bold', transform=axes[1, col].transAxes)\n",
    "    # fig.set_figheight(15)\n",
    "    fig.set_figwidth(20)\n",
    "\n",
    "    \n",
    "\n",
    "    visualize_saliency_overlay(axes[0, 0], original_image, grad_cam, grad_probs, grad_idx, classes);\n",
    "    visualize_saliency_overlay(axes[0, 2], original_image, score_cam, score_probs, score_idx, classes);\n",
    "    visualize_saliency_overlay(axes[0, 4], original_image, smoothgradpp_cam, smoothgradpp_probs, smoothgradpp_idx, classes);\n",
    "    visualize_saliency_overlay(axes[0, 6], original_image, layer_cam, layer_probs, layer_idx, classes);\n",
    "    \n",
    "    # for row in range(axes.shape[0]):\n",
    "    visualize_saliency_overlay(axes[1, 0], original_image, pertubed_grad_cam, pertubed_grad_probs, pertubed_grad_idx, classes);    \n",
    "    visualize_saliency_overlay(axes[1, 2], original_image, pertubed_score_cam, pertubed_score_probs, pertubed_score_idx, classes);\n",
    "    visualize_saliency_overlay(axes[1, 4], original_image, pertubed_smoothgradpp_cam, pertubed_smoothgradpp_probs, pertubed_smoothgradpp_idx, classes);    \n",
    "    visualize_saliency_overlay(axes[1, 6], original_image, pertubed_layer_cam, pertubed_layer_probs, pertubed_layer_idx, classes);\n",
    "    \n",
    "        \n",
    "    sim_grad, cc_grad, nss_grad, auc_grad, emd_grad, ior_grad = calculate_metrics(grad_cam, pertubed_grad_cam, mask) \n",
    "    text_grad = f\"Sim: {sim_grad:.2f}\\nCC: {cc_grad:.2f}\\nNSS: {nss_grad:.2f}\\nAUC: {auc_grad:.2f}\\nEMD: {emd_grad:.2f}\\nIOR: {ior_grad:.2f}\"\n",
    "    \n",
    "    sim_score, cc_score, nss_score, auc_score, emd_score, ior_score = calculate_metrics(score_cam, pertubed_score_cam, mask) \n",
    "    text_score = f\"Sim: {sim_score:.2f}\\nCC: {cc_score:.2f}\\nNSS: {nss_score:.2f}\\nAUC: {auc_score:.2f}\\nEMD: {emd_score:.2f}\\nIOR: {ior_score:.2f}\"\n",
    "    \n",
    "    sim_smooth, cc_smooth, nss_smooth, auc_smooth, emd_smooth, ior_smooth = calculate_metrics(smoothgradpp_cam, pertubed_smoothgradpp_cam, mask) \n",
    "    text_smooth = f\"Sim: {sim_smooth:.2f}\\nCC: {cc_smooth:.2f}\\nNSS: {nss_smooth:.2f}\\nAUC: {auc_smooth:.2f}\\nEMD: {emd_smooth:.2f}\\nIOR: {ior_smooth:.2f}\"\n",
    "    \n",
    "    sim_layer, cc_layer, nss_layer, auc_layer, emd_layer, ior_layer = calculate_metrics(layer_cam, pertubed_layer_cam, mask) \n",
    "    text_layer = f\"Sim: {sim_layer:.2f}\\nCC: {cc_layer:.2f}\\nNSS: {nss_layer:.2f}\\nAUC: {auc_layer:.2f}\\nEMD: {emd_layer:.2f}\\nIOR: {ior_layer:.2f}\"\n",
    "        \n",
    "    #     axis.text(2*10, axis.get_ylim()[0]-2*10, f\"$IOR={ior:.2f}$\", fontsize=15, color=\"white\", bbox={'facecolor' : \"red\", \"alpha\" : 0.5, \"pad\" : 5})\n",
    "    axes[1, 1].imshow(text_to_rgba(text_grad, color=\"blue\", fontsize=10, dpi=200))\n",
    "    axes[1, 3].imshow(text_to_rgba(text_score, color=\"blue\", fontsize=10, dpi=200))\n",
    "    axes[1, 5].imshow(text_to_rgba(text_smooth, color=\"blue\", fontsize=10, dpi=200))\n",
    "    axes[1, 7].imshow(text_to_rgba(text_layer, color=\"blue\", fontsize=10, dpi=200))\n",
    "    \n",
    "\n",
    "    for technique in techniques:\n",
    "        for metric in metrics:\n",
    "            if technique == \"GradCAM\":\n",
    "                calculated_value = locals()[metric.lower() + \"_grad\"]\n",
    "            elif technique == \"ScoreCAM\":\n",
    "                calculated_value = locals()[metric.lower() + \"_score\"]\n",
    "            elif technique == \"SmoothGradCAMpp\":\n",
    "                calculated_value = locals()[metric.lower() + \"_smooth\"]\n",
    "            elif technique == \"LayerCAM\":\n",
    "                calculated_value = locals()[metric.lower() + \"_layer\"]\n",
    "                # Append the calculated metric to the appropriate list\n",
    "            metrics_values[technique][metric].append(calculated_value)\n",
    "\n",
    "    for technique in techniques:\n",
    "        for metric in metrics:\n",
    "            metrics_values[technique][metric] = [float(value) for value in metrics_values[technique][metric]]\n",
    "\n",
    "    \n",
    "    gradcam = np.append(gradcam, pertubed_grad_cam)\n",
    "    scorecam = np.append(scorecam, pertubed_score_cam)\n",
    "    smoothgradcampp = np.append(smoothgradcampp, pertubed_smoothgradpp_cam)\n",
    "    layercam = np.append(layercam, pertubed_layer_cam)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # fig.suptitle(\"GradCAM vs ScoreCAM\", fontsize=16, fontweight=\"bold\", y=0.9)\n",
    "    # fig.show()\n",
    "    fig.savefig(f\"/project/validating_attribution_techniques/shardul/data/Doc/Experimentation/Inter_Model/Images/InceptionV3/ResnNet50_InceptionV3_{img_idx}.png\")\n",
    "    plt.close(fig)\n",
    "    np.save(f\"/project/validating_attribution_techniques/shardul/data/Doc/Experimentation/Inter_Model/InceptionV3/Img_{img_idx}/Saliency/{models[2]}_GradCAM_saliency_idx_{img_idx}.npy\", gradcam)\n",
    "    np.save(f\"/project/validating_attribution_techniques/shardul/data/Doc/Experimentation/Inter_Model/InceptionV3/Img_{img_idx}/Saliency/{models[2]}_ScoreCAM_saliency_idx_{img_idx}.npy\", scorecam)\n",
    "    np.save(f\"/project/validating_attribution_techniques/shardul/data/Doc/Experimentation/Inter_Model/InceptionV3/Img_{img_idx}/Saliency/{models[2]}_SmoothGradCAM_saliency_idx_{img_idx}.npy\", smoothgradcampp)\n",
    "    np.save(f\"/project/validating_attribution_techniques/shardul/data/Doc/Experimentation/Inter_Model/InceptionV3/Img_{img_idx}/Saliency/{models[2]}_LayerCAM_saliency_idx_{img_idx}.npy\", layercam)\n",
    "\n",
    "    output_file = f\"/project/validating_attribution_techniques/shardul/data/Doc/Experimentation/Inter_Model/InceptionV3/Img_{img_idx}/Results/metrics_{models[0]}_{img_idx}.json\"\n",
    "    if os.path.exists(output_file):\n",
    "        os.remove(output_file)\n",
    "    with open(output_file, 'w') as json_file:\n",
    "        json.dump(metrics_values, json_file, indent=4)\n",
    "\n",
    "    del sim_layer, cc_layer, nss_layer, auc_layer, emd_layer, ior_layer\n",
    "    del sim_smooth, cc_smooth, nss_smooth, auc_smooth, emd_smooth, ior_smooth\n",
    "    del sim_score, cc_score, nss_score, auc_score, emd_score, ior_score\n",
    "    del sim_grad, cc_grad, nss_grad, auc_grad, emd_grad, ior_grad\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d68bdbe6-d4bd-4bb9-a716-a994eb83cd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardise NSS and EMD\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Load metrics_data for each CAM method\n",
    "cam_types = [\"GradCAM\", \"ScoreCAM\", \"SmoothGradCAMpp\", \"LayerCAM\"]\n",
    "standardized_metrics = {}\n",
    "\n",
    "for cam_type in cam_types:\n",
    "    data = np.load(f'/project/validating_attribution_techniques/shardul/data/Doc/Tables/Occlusion/ResNet50/Patch_60/{cam_type}_metrics_data.npy')\n",
    "\n",
    "    # Standardize NSS and EMD values\n",
    "    nss_idx = 2  # Assuming NSS is at index 2 in your metrics data\n",
    "    emd_idx = 4  # Assuming EMD is at index 4 in your metrics data\n",
    "\n",
    "    nss_values = data[:, :, nss_idx]\n",
    "    emd_values = data[:, :, emd_idx]\n",
    "\n",
    "    # Standardize NSS to be between -1 and 1\n",
    "    nss_values = (nss_values - np.min(nss_values)) / (np.max(nss_values) - np.min(nss_values)) * 2 - 1\n",
    "\n",
    "    # Standardize EMD to be between 0 and 1\n",
    "    emd_values = (emd_values - np.min(emd_values)) / (np.max(emd_values) - np.min(emd_values))\n",
    "\n",
    "    # Calculate mean, min, max, std for standardized values\n",
    "    mean_nss = np.mean(nss_values, axis=(0, 1))\n",
    "    min_nss = np.min(nss_values, axis=(0, 1))\n",
    "    max_nss = np.max(nss_values, axis=(0, 1))\n",
    "    std_nss = np.std(nss_values, axis=(0, 1))\n",
    "\n",
    "    mean_emd = np.mean(emd_values, axis=(0, 1))\n",
    "    min_emd = np.min(emd_values, axis=(0, 1))\n",
    "    max_emd = np.max(emd_values, axis=(0, 1))\n",
    "    std_emd = np.std(emd_values, axis=(0, 1))\n",
    "\n",
    "    # Store the standardized metrics\n",
    "    standardized_metrics[cam_type] = {\n",
    "        \"mean_nss\": mean_nss,\n",
    "        \"min_nss\": min_nss,\n",
    "        \"max_nss\": max_nss,\n",
    "        \"std_nss\": std_nss,\n",
    "        \"mean_emd\": mean_emd,\n",
    "        \"min_emd\": min_emd,\n",
    "        \"max_emd\": max_emd,\n",
    "        \"std_emd\": std_emd\n",
    "    }\n",
    "\n",
    "# Now you have the standardized metrics for NSS and EMD values for each CAM method\n",
    "# Access them as needed, e.g., standardized_metrics[\"GradCAM\"][\"mean_nss\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7759afab-0968-4000-812d-daf29d36eeae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAM Type: GradCAM\n",
      "Standardized NSS:\n",
      "Min NSS: -1.0\n",
      "Max NSS: 1.0\n",
      "Mean NSS: 0.3356285750421901\n",
      "Std NSS: 0.2874527973034562\n",
      "Standardized EMD:\n",
      "Min EMD: 0.0\n",
      "Max EMD: 1.0\n",
      "Mean EMD: 0.17657936676143915\n",
      "Std EMD: 0.14239095997303\n",
      "\n",
      "CAM Type: ScoreCAM\n",
      "Standardized NSS:\n",
      "Min NSS: -1.0\n",
      "Max NSS: 1.0\n",
      "Mean NSS: 0.1215049442393329\n",
      "Std NSS: 0.2653152416464684\n",
      "Standardized EMD:\n",
      "Min EMD: 0.0\n",
      "Max EMD: 1.0\n",
      "Mean EMD: 0.16777511569667994\n",
      "Std EMD: 0.11850037915199549\n",
      "\n",
      "CAM Type: SmoothGradCAMpp\n",
      "Standardized NSS:\n",
      "Min NSS: -1.0\n",
      "Max NSS: 1.0\n",
      "Mean NSS: 0.14539225647870968\n",
      "Std NSS: 0.288483241997854\n",
      "Standardized EMD:\n",
      "Min EMD: 0.0\n",
      "Max EMD: 1.0\n",
      "Mean EMD: 0.23727407636897851\n",
      "Std EMD: 0.1335793107801358\n",
      "\n",
      "CAM Type: LayerCAM\n",
      "Standardized NSS:\n",
      "Min NSS: -1.0\n",
      "Max NSS: 1.0\n",
      "Mean NSS: 0.1915510698004072\n",
      "Std NSS: 0.2889486121673846\n",
      "Standardized EMD:\n",
      "Min EMD: 0.0\n",
      "Max EMD: 1.0\n",
      "Mean EMD: 0.16903289777990854\n",
      "Std EMD: 0.11720133821701863\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have the standardized_metrics dictionary from the previous code\n",
    "\n",
    "for cam_type, metrics in standardized_metrics.items():\n",
    "    print(f\"CAM Type: {cam_type}\")\n",
    "    print(\"Standardized NSS:\")\n",
    "    print(f\"Min NSS: {metrics['min_nss']}\")\n",
    "    print(f\"Max NSS: {metrics['max_nss']}\")\n",
    "    print(f\"Mean NSS: {metrics['mean_nss']}\")\n",
    "    print(f\"Std NSS: {metrics['std_nss']}\")\n",
    "\n",
    "    print(\"Standardized EMD:\")\n",
    "    print(f\"Min EMD: {metrics['min_emd']}\")\n",
    "    print(f\"Max EMD: {metrics['max_emd']}\")\n",
    "    print(f\"Mean EMD: {metrics['mean_emd']}\")\n",
    "    print(f\"Std EMD: {metrics['std_emd']}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac9f045-69dc-4303-967f-3d53df04cb99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
