{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "760f27a8-f382-43e5-84c2-c0401a14a52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp attribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98693184-528d-4bcc-b734-b88e361e61fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import os\n",
    "os.chdir(\"/project/validating_attribution_techniques/torchCAM\")\n",
    "from torchcam.methods.gradient import SmoothGradCAMpp, GradCAMpp, GradCAM, LayerCAM\n",
    "from torchcam.methods.activation import ScoreCAM\n",
    "from torchcam.utils import overlay_mask\n",
    "from torchvision.models import resnet50, resnet18, vgg16, inception_v3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54745325-98fe-4610-b8a8-d166836c113c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "os.chdir(\"/project/validating_attribution_techniques/\")\n",
    "from commons.api.viz import visualize_saliency_overlay\n",
    "from commons.api.imagenet_tiny import get_imagenet_classes, get_random_images\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81e48395-b5db-4fd8-a45e-6df9f55b1a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "classes = get_imagenet_classes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7725ef8c-ab07-4ecf-9a12-154e31e91ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def attribution(model, input_tensor, method, target_layer = \"layer4\"):\n",
    "    \"\"\"\n",
    "    Function used to generate a saliency map using different saliency generation techniques like GradCAM, ScoreCAM, SmoothGradCAMpp, LayerCAM.\n",
    "\n",
    "    Args:\n",
    "        model (torchvision.models): Model used in finding the class from an image.\n",
    "            Example: ResNet50\n",
    "            Import the model: from torchvision.models import resnet50\n",
    "            Create an instance: model_resnet50 = resnet50(pretrained=True).eval()\n",
    "\n",
    "        input_tensor (torch.Tensor): An input image transformed into a tensor with shape (3, w, h),\n",
    "            where w is the width and h is the height.\n",
    "\n",
    "        method (str): Name of the saliency generation method.\n",
    "\n",
    "        target_layer (str or torch.nn.Module): The target layer for feature extraction. You can provide either the layer name as a string (e.g., \"layer4\") or the actual layer from the model.\n",
    "\n",
    "    Returns:\n",
    "        cam_mask (numpy.ndarray): The saliency map generated by the specified method.\n",
    "        idx (int): The index of the predicted class with the highest probability.\n",
    "        probs (numpy.ndarray): Class probabilities for the input image.\n",
    "\n",
    "    Usage:\n",
    "    - Call this function to generate a saliency map for the given input image using the specified method.\n",
    "    - The target layer can be provided as either a string or the actual layer from the model.\n",
    "    \"\"\"\n",
    "    def method1(method, model, target_layer):\n",
    "        \"\"\"\n",
    "        Factory function to create an instance of a saliency method for a given model and target layer.\n",
    "    \n",
    "        Args:\n",
    "            method (str): The name of the saliency generation method.\n",
    "            model (torchvision.models): The model for which the saliency method instance is created.\n",
    "            target_layer (str or torch.nn.Module): The target layer for feature extraction.\n",
    "    \n",
    "        Returns:\n",
    "            torchcam.CAM: An instance of the specified saliency method for the given model and target layer.\n",
    "    \n",
    "        Usage:\n",
    "        - Call this function to create an instance of a saliency method based on the method name and target layer.\n",
    "        \"\"\"\n",
    "        if method == \"ScoreCAM\":\n",
    "            return ScoreCAM(model, target_layer)\n",
    "        elif method == \"GradCAM\":\n",
    "            return GradCAM(model, target_layer)\n",
    "        elif method == \"SmoothGradCAMpp\":\n",
    "            return SmoothGradCAMpp(model, target_layer)\n",
    "        elif method == \"LayerCAM\":\n",
    "            return LayerCAM(model, target_layer)\n",
    "            \n",
    "    attr = method1(method, model, target_layer)\n",
    "    with attr as extractor:  \n",
    "        # Preprocess your data and feed it to the model\n",
    "        out = model(input_tensor.unsqueeze(0))\n",
    "        # Retrieve the CAM by passing the class index and the model output\n",
    "        activation_map = extractor(out.squeeze(0).argmax().item(), out)\n",
    "    # Apply softmax to calculate class probabilities\n",
    "    probs = torch.softmax(out, dim=1)\n",
    "    idx = probs.argmax()\n",
    "    \n",
    "    # Get the class with the highest probability for each input\n",
    "    pred_class = torch.argmax(probs, dim=1)\n",
    "    probs = probs.detach().cpu().numpy()\n",
    "    \n",
    "    # To extract the class ID and probability for the first input (if it's a batch):\n",
    "    class_id = pred_class[0].item()\n",
    "    probability = probs[0, class_id].item()\n",
    "    cam_mask =  activation_map[0].cpu().numpy().squeeze(0)\n",
    "    return cam_mask, idx, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e23ec15b-cdf9-4676-92cd-3803b8fe46b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# os.chdir(\"/project/validating_attribution_techniques/shardul/api_notebooks/\")\n",
    "from nbdev.export import nb_export\n",
    "nb_export('/project/validating_attribution_techniques/shardul/api_notebooks/attribution.ipynb', '/project/validating_attribution_techniques/commons/api/method/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99a800e-c346-4c79-ada9-6e251ae155f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
