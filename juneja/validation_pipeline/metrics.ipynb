{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12269bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "736e5d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "from skimage import img_as_float\n",
    "from skimage import exposure\n",
    "\n",
    "def normalize(x, method='standard', axis=None):\n",
    "    '''Normalizes the input with specified method.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    res : numpy.ndarray\n",
    "        Normalized array.\n",
    "    '''\n",
    "    # TODO: Prevent divided by zero if the map is flat\n",
    "    x = np.array(x, copy=False)\n",
    "    if axis is not None:\n",
    "        y = np.rollaxis(x, axis).reshape([x.shape[axis], -1])\n",
    "        shape = np.ones(len(x.shape))\n",
    "        shape[axis] = x.shape[axis]\n",
    "        if method == 'standard':\n",
    "            res = (x - np.mean(y, axis=1).reshape(shape)) / np.std(y, axis=1).reshape(shape)\n",
    "        elif method == 'range':\n",
    "            res = (x - np.min(y, axis=1).reshape(shape)) / (np.max(y, axis=1) - np.min(y, axis=1)).reshape(shape)\n",
    "        elif method == 'sum':\n",
    "            res = x / np.float_(np.sum(y, axis=1).reshape(shape))\n",
    "        else:\n",
    "            raise ValueError('method not in {\"standard\", \"range\", \"sum\"}')\n",
    "    else:\n",
    "        if method == 'standard':\n",
    "            res = (x - np.mean(x)) / np.std(x)\n",
    "        elif method == 'range':\n",
    "            res = (x - np.min(x)) / (np.max(x) - np.min(x))\n",
    "        elif method == 'sum':\n",
    "            res = x / float(np.sum(x))\n",
    "        else:\n",
    "            raise ValueError('method not in {\"standard\", \"range\", \"sum\"}')\n",
    "    return res\n",
    "\n",
    "\n",
    "def match_hist(image, cdf, bin_centers, nbins=256):\n",
    "    '''\n",
    "    References\n",
    "    ----------\n",
    "    [1] Matlab implementation histoMatch(MTX, N, X) by Simoncelli, 7/96.\n",
    "    '''\n",
    "    image = img_as_float(image)\n",
    "    old_cdf, old_bin = exposure.cumulative_distribution(image, nbins) # Unlike [1], we didn't add small positive number to the histogram\n",
    "    new_bin = np.interp(old_cdf, cdf, bin_centers)\n",
    "    out = np.interp(image.ravel(), old_bin, new_bin)\n",
    "    return out.reshape(image.shape)\n",
    "\n",
    "def normalize_map(map):\n",
    "    min_value = np.min(map)\n",
    "    max_value = np.max(map)\n",
    "    normalized_map = (map - min_value) / (max_value - min_value)\n",
    "    return normalized_map\n",
    "\n",
    "def SIM(saliency_map1, saliency_map2):\n",
    "    ''' \n",
    "    saliency maps when viewed as distributions, histogram intersection\n",
    "    (SIM=1 means the distributions are identical).\n",
    "    '''\n",
    "    map1 = np.array(saliency_map1, copy=False)\n",
    "    map2 = np.array(saliency_map2, copy=False)\n",
    "    if map1.shape != map2.shape:\n",
    "        map1 = resize(map1, map2.shape, order=3, mode='nearest') # bi-cubic/nearest is what Matlab imresize() does by default\n",
    "    # Normalize the two maps to have values between [0,1] and sum up to 1\n",
    "    map1 = normalize(map1, method='range')\n",
    "    map2 = normalize(map2, method='range')\n",
    "    map1 = normalize(map1, method='sum')\n",
    "    map2 = normalize(map2, method='sum')\n",
    "    # Compute histogram intersection\n",
    "    intersection = np.minimum(map1, map2)\n",
    "    return np.sum(intersection)\n",
    "\n",
    "def CC(saliency_map1, saliency_map2):\n",
    "    '''\n",
    "    Pearson's correlation coefficient between two different saliency maps\n",
    "    (CC=-1 inverse linear co-relation for CC=0 for uncorrelated maps, CC=1 for perfect linear correlation).\n",
    "    '''\n",
    "    map1 = np.array(saliency_map1, copy=False)\n",
    "    map2 = np.array(saliency_map2, copy=False)\n",
    "    if map1.shape != map2.shape:\n",
    "        map1 = resize(map1, map2.shape, order=3, mode='nearest') # bi-cubic/nearest is what Matlab imresize() does by default\n",
    "    # Normalize the two maps to have zero mean and unit std\n",
    "    map1 = normalize(map1, method='standard')\n",
    "    map2 = normalize(map2, method='standard')\n",
    "    # Compute correlation coefficient\n",
    "    return np.corrcoef(map1.ravel(), map2.ravel())[0,1]\n",
    "\n",
    "def NSS(saliency_map, fixation_map):\n",
    "    '''\n",
    "    Normalized scanpath saliency of a saliency map, defined as the mean value of normalized (i.e., standardized) saliency map at fixation locations.\n",
    "    You can think of it as a z-score. (Larger value implies better performance.)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    saliency_map : real-valued matrix\n",
    "        If the two maps are different in shape, saliency_map will be resized to match fixation_map..\n",
    "    fixation_map : binary matrix\n",
    "        Human fixation map (1 for fixated location, 0 for elsewhere).\n",
    "    Returns\n",
    "    -------\n",
    "    NSS : float, positive\n",
    "    '''\n",
    "    s_map = np.array(saliency_map, copy=False)\n",
    "    f_map = np.array(fixation_map, copy=False) > 0.5\n",
    "    if s_map.shape != f_map.shape:\n",
    "        s_map = resize(s_map, f_map.shape)\n",
    "    # Normalize saliency map to have zero mean and unit std\n",
    "    s_map = normalize(s_map, method='standard')\n",
    "    # Mean saliency value at fixation locations\n",
    "    return np.mean(s_map[f_map])\n",
    "\n",
    "\n",
    "def AUC_Judd(saliency_map, fixation_map, jitter=True):\n",
    "    '''\n",
    "    AUC stands for Area Under ROC Curve.\n",
    "    \n",
    "    True positive (tp) rate correspond to the ratio of saliency map values above threshold\n",
    "    at fixation locations to the total number of fixation locations.\n",
    "    \n",
    "    False positive (fp) rate correspond to the ratio of saliency map values above threshold\n",
    "    at all other locations to the total number of possible other locations (non-fixated image pixels).\n",
    "\n",
    "    AUC=0.5 is chance level.\n",
    "    '''\n",
    "    \n",
    "    saliency_map = np.array(saliency_map, copy=False)\n",
    "    fixation_map = np.array(fixation_map, copy=False) > 0.5\n",
    "    # If there are no fixation to predict, return NaN\n",
    "    if not np.any(fixation_map):\n",
    "        print('no fixation to predict')\n",
    "        return np.nan\n",
    "    # Make the saliency_map the size of the fixation_map\n",
    "    if saliency_map.shape != fixation_map.shape:\n",
    "        saliency_map = resize(saliency_map, fixation_map.shape, order=3, mode='nearest')\n",
    "    # Jitter the saliency map slightly to disrupt ties of the same saliency value\n",
    "    if jitter:\n",
    "        saliency_map += random.rand(*saliency_map.shape) * 1e-7\n",
    "    # Normalize saliency map to have values between [0,1]\n",
    "    saliency_map = normalize(saliency_map, method='range')\n",
    "\n",
    "    S = saliency_map.ravel()\n",
    "    F = fixation_map.ravel()\n",
    "    S_fix = S[F] # Saliency map values at fixation locations\n",
    "    n_fix = len(S_fix)\n",
    "    n_pixels = len(S)\n",
    "    # Calculate AUC\n",
    "    thresholds = sorted(S_fix, reverse=True)\n",
    "    tp = np.zeros(len(thresholds)+2)\n",
    "    fp = np.zeros(len(thresholds)+2)\n",
    "    tp[0] = 0; tp[-1] = 1\n",
    "    fp[0] = 0; fp[-1] = 1\n",
    "    for k, thresh in enumerate(thresholds):\n",
    "        above_th = np.sum(S >= thresh) # Total number of saliency map values above threshold\n",
    "        tp[k+1] = (k + 1) / float(n_fix) # Ratio saliency map values at fixation locations above threshold\n",
    "        fp[k+1] = (above_th - k - 1) / float(n_pixels - n_fix) # Ratio other saliency map values above threshold\n",
    "    return np.trapz(tp, fp) # y, x\n",
    "\n",
    "def emd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adaee953",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.export import nb_export\n",
    "nb_export('metrics.ipynb', './') # arg1 : name of notebook, arg2 : location of the export relative to the current directory"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
